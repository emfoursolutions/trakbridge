# =============================================================================
# TrakBridge GitLab CI/CD Pipeline - Enhanced with Comprehensive Features
# =============================================================================
#
# Comprehensive CI/CD pipeline converted from GitHub Actions with GitLab enhancements:
# - Multi-environment deployments (development, staging, production)
# - Comprehensive testing suite (unit, integration, E2E, performance)
# - Enhanced security scanning with GitLab's built-in features
# - Container registry integration and multi-architecture builds
# - Native GitLab Slack app integration for notifications
# - Environment management with approval workflows
#
# =============================================================================

stages:
  - validate
  - test
  - build
  - security
  - deploy

# Global variables - OPTIMIZED
variables:
  # Git configuration - CRITICAL for setuptools-scm
  GIT_DEPTH: 0
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: none
  GIT_FETCH_EXTRA_FLAGS: "--tags"

  # Python configuration
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  PYTHON_VERSION: "3.12"

  # Build optimization
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_CACHE_DIR: "false"

  # Application configuration
  APP_NAME: "trakbridge"

  # Container registry configuration
  REGISTRY: "docker.io"
  IMAGE_NAME: "$REGISTRY/$DOCKERHUB_USERNAME/$APP_NAME"

  # Test configuration
  PYTEST_ADDOPTS: "--strict-markers --strict-config --tb=short"
  COVERAGE_FILE: "$CI_PROJECT_DIR/.coverage"

  # Security scanning
  SAST_EXCLUDED_PATHS: "tests, docs, scripts"
  SECURE_LOG_LEVEL: "info"

# Enhanced cache configuration
cache:
  - key: "pip-$CI_COMMIT_REF_SLUG-$PYTHON_VERSION"
    paths:
      - .pip-cache/
    policy: pull-push
  - key: "python-venv-$CI_COMMIT_REF_SLUG-$PYTHON_VERSION"
    paths:
      - .venv/
    policy: pull-push

# =============================================================================
# VALIDATE STAGE
# =============================================================================

validate-yaml:
  stage: validate
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 5m
  before_script:
    - pip install --no-cache-dir pyyaml
  script: |
    # Check if YAML files exist before validating
    if ls config/settings/*.yaml 1> /dev/null 2>&1; then
      echo "Validating YAML files..."
      for file in config/settings/*.yaml; do
        echo "Validating $file"
        python -c "import yaml; yaml.safe_load(open('$file'))"
      done
      echo "All YAML configuration files are valid"
    else
      echo "No YAML files found to validate"
    fi
  rules:
    - changes:
        - "config/**/*.yaml"
        - "config/**/*.yml"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

validate-requirements:
  stage: validate
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - apt-get update && apt-get install -y git
    - pip install --upgrade pip
    - pip install --no-cache-dir pip-tools pip-audit
  script: |
    echo "Validating requirements.txt format..."

    if [ -f "requirements.txt" ]; then
      python -m pip install --dry-run -r requirements.txt
      echo "Requirements are valid and installable"
    else
      echo "No requirements.txt found"
    fi
    
    echo "Checking requirements for known vulnerabilities..."

    # Always create the audit report file
    if [ -f "requirements.txt" ]; then
      # Create a simple JSON report structure to avoid upload issues
      echo '{"vulnerabilities": []}' > audit-report.json
      
      # Run audit but don't fail the job on vulnerabilities
      if timeout 300 pip-audit --requirement requirements.txt --format json --output temp-audit.json; then
        mv temp-audit.json audit-report.json
      else
        echo "Audit completed with warnings or timeout"
      fi
      
      echo "Requirements security check completed"
    else
      echo '{"vulnerabilities": [], "message": "No requirements.txt found"}' > audit-report.json
    fi
  artifacts:
    reports:
      # Only include SAST report if it contains actual vulnerabilities
      sast: audit-report.json
    paths:
      - audit-report.json
    expire_in: 1 day
    when: always
  rules:
    - changes:
        - "requirements.txt"
        - "requirements.in"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

validate-pyproject:
  stage: validate
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - apt-get update && apt-get install -y git
    - pip install --upgrade pip
    - pip install --no-cache-dir tomli validate-pyproject build setuptools-scm
  script: |
    echo "Validating pyproject.toml..."
    mkdir -p dist

    if [ -f "pyproject.toml" ]; then
      python -c "import tomli; tomli.load(open('pyproject.toml', 'rb'))"
      validate-pyproject pyproject.toml
      echo "Testing setuptools-scm version detection..."
      python -c "import setuptools_scm; print(f'Version: {setuptools_scm.get_version()}')"
      echo "Testing package build configuration..."
      python -m build --sdist --wheel --outdir dist/ .
      echo "pyproject.toml validation completed"
    else
      echo "No pyproject.toml found"
      echo "placeholder" > dist/.gitkeep
    fi
  artifacts:
    paths:
      - dist/
    expire_in: 1 hour
    when: always
  rules:
    - changes:
        - "pyproject.toml"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# =============================================================================
# TESTING STAGE
# =============================================================================

code-quality:
  stage: test
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - apt-get update && apt-get install -y git jq
    - pip install --upgrade pip
    - pip install --no-cache-dir black flake8 isort
  script: |
    set +e  # Disable exit on error to ensure script always completes
    echo "Running code quality checks with GitLab reporting..."
    
    # Initialize Code Quality report
    echo '[]' > gl-code-quality-report.json
    
    # Run Black and generate report
    echo "Checking code formatting with Black..."
    if ! black --check --diff . > black-output.txt 2>&1 || true; then
      echo "Black formatting issues found"
      
      # Parse Black output and convert to GitLab Code Quality format
      while IFS= read -r line; do
        if [[ $line == *"would reformat"* ]]; then
          file=$(echo "$line" | grep -o '[^[:space:]]*\.py')
          if [[ -n "$file" ]]; then
            jq --null-input \
              --arg file "$file" \
              --arg description "Code formatting issue: file would be reformatted by Black" \
              --arg fingerprint "black-$file" \
              '{
                description: $description,
                check_name: "black",
                fingerprint: $fingerprint,
                severity: "minor",
                location: {
                  path: $file,
                  lines: {
                    begin: 1
                  }
                }
              }' >> black-issues.json
          fi
        fi
      done < black-output.txt
      
      if [[ -f black-issues.json ]]; then
        jq -s '.' black-issues.json > black-report.json
        jq '. + input' gl-code-quality-report.json black-report.json > temp.json && mv temp.json gl-code-quality-report.json
      fi
    fi
    
    # Run Flake8 and generate report
    echo "Checking code style with Flake8..."
    if ! flake8 . --max-line-length=100 --extend-ignore=E203,W503 \
      --exclude=.git,__pycache__,build,dist,.venv \
      --format='%(path)s:%(row)d:%(col)d: %(code)s %(text)s' > flake8-output.txt 2>&1 || true; then
      echo "Flake8 issues found"
      
      # Convert Flake8 output to GitLab Code Quality format
      while IFS= read -r line; do
        if [[ $line == *":"* ]]; then
          file=$(echo "$line" | cut -d: -f1)
          line_num=$(echo "$line" | cut -d: -f2)
          col_num=$(echo "$line" | cut -d: -f3)
          error_code=$(echo "$line" | cut -d: -f4 | awk '{print $1}')
          message=$(echo "$line" | cut -d: -f4 | cut -d' ' -f2-)
          
          jq --null-input \
            --arg file "$file" \
            --arg line "$line_num" \
            --arg description "Flake8 $error_code: $message" \
            --arg fingerprint "flake8-$file-$line_num-$error_code" \
            '{
              description: $description,
              check_name: "flake8",
              fingerprint: $fingerprint,
              severity: "minor",
              location: {
                path: $file,
                lines: {
                  begin: ($line | tonumber)
                }
              }
            }' >> flake8-issues.json
        fi
      done < flake8-output.txt
      
      if [[ -f flake8-issues.json ]]; then
        jq -s '.' flake8-issues.json > flake8-report.json
        jq '. + input' gl-code-quality-report.json flake8-report.json > temp.json && mv temp.json gl-code-quality-report.json
      fi
    fi
    
    # Run isort and generate report
    echo "Checking import sorting with isort..."
    if ! isort --check-only --diff . > isort-output.txt 2>&1 || true; then
      echo "Import sorting issues found"
      
      # Parse isort output and convert to GitLab Code Quality format
      while IFS= read -r line; do
        if [[ $line == *"Fixing"* ]] || [[ $line == *"Skipped"* ]]; then
          file=$(echo "$line" | grep -o '[^[:space:]]*\.py')
          if [[ -n "$file" ]]; then
            jq --null-input \
              --arg file "$file" \
              --arg description "Import sorting issue: imports not sorted according to isort configuration" \
              --arg fingerprint "isort-$file" \
              '{
                description: $description,
                check_name: "isort",
                fingerprint: $fingerprint,
                severity: "minor",
                location: {
                  path: $file,
                  lines: {
                    begin: 1
                  }
                }
              }' >> isort-issues.json
          fi
        fi
      done < isort-output.txt
      
      if [[ -f isort-issues.json ]]; then
        jq -s '.' isort-issues.json > isort-report.json
        jq '. + input' gl-code-quality-report.json isort-report.json > temp.json && mv temp.json gl-code-quality-report.json
      fi
    fi
    
    # Show summary
    issue_count=$(jq 'length' gl-code-quality-report.json)
    echo "Code quality check completed: $issue_count issues found"
    
    if [[ $issue_count -gt 0 ]]; then
      echo "Code quality issues detected - see GitLab Code Quality report"
    else
      echo "All code quality checks passed"
    fi
    
    # Always exit successfully regardless of quality issues
    exit 0
  
  artifacts:
    reports:
      codequality: gl-code-quality-report.json
    paths:
      - gl-code-quality-report.json
      - black-output.txt
      - flake8-output.txt
      - isort-output.txt
    expire_in: 1 week
    when: always
  
  allow_failure: false
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# =============================================================================
# UNIT TESTING STAGE - Comprehensive Test Suite
# =============================================================================

# PostgreSQL service for integration tests
.postgres_service: &postgres_service
  services:
    - name: postgres:15-alpine
      alias: postgres
      variables:
        POSTGRES_DB: test_db
        POSTGRES_USER: test_user
        POSTGRES_PASSWORD: test_password
        POSTGRES_HOST_AUTH_METHOD: trust

# Unit tests with coverage
unit-tests:
  stage: test
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 20m
  coverage: '/TOTAL.+?(\d+\%)$/'
  
  variables:
    # Use SQLite for fast unit tests
    DB_TYPE: "sqlite"
    FLASK_ENV: "testing"
    SECRET_KEY: "test-secret-key-for-gitlab-ci"
    TRAKBRIDGE_ENCRYPTION_KEY: "test-encryption-key-for-gitlab-ci-12345"
    COVERAGE_THRESHOLD: "20"
    # Ensure Python can find the project modules
    PYTHONPATH: "${CI_PROJECT_DIR}:${PYTHONPATH:-}"
  
  before_script:
    - apt-get update -qq && apt-get install -y -qq git curl build-essential
    - pip install --upgrade pip
    - pip install -e ".[dev]"
  
  script: |
    echo "Running comprehensive unit test suite..."
    
    # Create unit test directory if it doesn't exist

    if [ ! -d "tests/unit" ]; then
      echo "No unit tests found - creating test directory structure"
      mkdir -p tests/unit
      echo "# Unit tests directory created" > tests/unit/__init__.py
      
      # Create basic unit test
      cat > tests/unit/test_basic_unit.py << 'EOF'
    """Basic unit tests for TrakBridge."""
    import pytest
    from app import create_app
    
    def test_app_creation():
        """Test that the Flask app can be created."""
        app = create_app('testing')
        assert app is not None
        assert app.config['TESTING'] is True
    
    def test_health_endpoint():
        """Test the health endpoint."""
        app = create_app('testing')
        with app.test_client() as client:
            response = client.get('/api/health')
            assert response.status_code == 200
            
    def test_basic_functionality():
        """Test basic application functionality."""
        app = create_app('testing')
        assert app.name == 'app'
    EOF
    fi
    
    # Run tests with comprehensive coverage reporting

    pytest tests/unit/ -v \
      --cov=. \
      --cov-report=xml \
      --cov-report=html \
      --cov-report=term-missing \
      --cov-fail-under=$COVERAGE_THRESHOLD \
      --cov-branch \
      --tb=short \
      --maxfail=10 \
      --durations=10 \
      --junitxml=unit-test-results.xml
    
    echo "Unit tests completed"
  
  artifacts:
    reports:
      junit: unit-test-results.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - htmlcov/
      - coverage.xml
      - unit-test-results.xml
      - tests/unit/
    expire_in: 14 days
  
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# Integration tests
integration-tests:
  stage: test
  image: python:${PYTHON_VERSION}-slim
  <<: *postgres_service
  tags:
    - trakbridge-ci
  timeout: 15m
  
  variables:
    # Use PostgreSQL for production-like integration tests
    DB_TYPE: "postgresql"
    DATABASE_URL: "postgresql://test_user:test_password@postgres:5432/test_db"
    FLASK_ENV: "testing"
    SECRET_KEY: "test-secret-key-for-gitlab-ci"
    TRAKBRIDGE_ENCRYPTION_KEY: "test-encryption-key-for-gitlab-ci-12345"
    # Ensure Python can find the project modules
    PYTHONPATH: "${CI_PROJECT_DIR}:${PYTHONPATH:-}"
  
  before_script:
    - apt-get update -qq && apt-get install -y -qq git curl build-essential
    - pip install --upgrade pip
    - pip install -e ".[dev]"
  
  script: |
    echo "Running integration tests..."
    
    # Create integration test directory if it doesn't exist

    if [ ! -d "tests/integration" ]; then
      echo "No integration tests found - creating test directory structure"
      mkdir -p tests/integration
      echo "# Integration tests directory created" > tests/integration/__init__.py
      
      # Create basic integration test
      cat > tests/integration/test_basic_integration.py << 'EOF'
    """Basic integration tests for TrakBridge."""
    import pytest
    from database import db
    from models.stream import Stream
    from app import create_app
    
    @pytest.fixture
    def app():
        """Create test application."""
        app = create_app('testing')
        with app.app_context():
            db.create_all()
            yield app
            db.drop_all()
    
    @pytest.fixture
    def client(app):
        """Create test client."""
        return app.test_client()
    
    def test_health_endpoint_integration(client):
        """Test health endpoint with database integration."""
        response = client.get('/api/health')
        assert response.status_code == 200
        
    def test_database_connection(app):
        """Test database connection and basic operations."""
        with app.app_context():
            # Test basic database operations
            stream = Stream(name="Integration Test Stream", plugin_type="garmin")
            db.session.add(stream)
            db.session.commit()
            
            retrieved = Stream.query.filter_by(name="Integration Test Stream").first()
            assert retrieved is not None
            assert retrieved.name == "Integration Test Stream"
            assert retrieved.plugin_type == "garmin"
    EOF
    fi
  
    # Run integration tests
    pytest tests/integration/ -v --tb=short --maxfail=5 --durations=10 --junitxml=integration-test-results.xml
    
    echo "Integration tests completed"
  
  artifacts:
    reports:
      junit: integration-test-results.xml
    paths:
      - integration-test-results.xml
      - tests/integration/
    expire_in: 14 days
  
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# =============================================================================
# SECURITY STAGE
# =============================================================================

bandit-sast:
  stage: security
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - apt-get update && apt-get install -y git
    - pip install --upgrade pip
    - pip install --no-cache-dir bandit[toml]
  script: |
    echo "Running Bandit security scan..."

    # Always create a bandit report file
    echo '{"metrics": {"_totals": {"nosec": 0, "skipped_tests": 0}}, "results": []}' > bandit-report.json
    
    # Run bandit on existing directories only
    SCAN_DIRS=""
    for dir in app.py services plugins routes models config; do
      if [ -e "$dir" ]; then
        SCAN_DIRS="$SCAN_DIRS $dir"
      fi
    done
    
    if [ -n "$SCAN_DIRS" ]; then
      bandit -r $SCAN_DIRS -f json -o temp-bandit.json || true
      if [ -f "temp-bandit.json" ]; then
        mv temp-bandit.json bandit-report.json
      fi
      echo "Bandit security scan completed"
    else
      echo "No directories found to scan"
    fi
  artifacts:
    reports:
      sast: bandit-report.json
    paths:
      - bandit-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

safety-check:
  stage: security
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 10m
  before_script:
    - apt-get update && apt-get install -y git jq
    - pip install --upgrade pip
    - pip install --no-cache-dir safety
  script: |
    echo "Running Safety vulnerability check with GitLab security reporting..."
    
    # Initialize GitLab security report
    cat > gl-dependency-scanning-report.json << 'EOF'
    {
      "version": "15.0.0",
      "vulnerabilities": [],
      "remediations": [],
      "scan": {
        "analyzer": {
          "id": "safety",
          "name": "Safety",
          "url": "https://pypi.org/project/safety/",
          "vendor": {
            "name": "PyUp.io"
          },
          "version": "latest"
        },
        "scanner": {
          "id": "safety",
          "name": "Safety",
          "url": "https://pypi.org/project/safety/",
          "vendor": {
            "name": "PyUp.io"
          },
          "version": "latest"
        },
        "type": "dependency_scanning",
        "start_time": "",
        "end_time": "",
        "status": "success"
      }
    }
    EOF
    
    # Set scan timestamps
    START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg start_time "$START_TIME" '.scan.start_time = $start_time' gl-dependency-scanning-report.json > temp.json && mv temp.json gl-dependency-scanning-report.json
    
    if [ -f "requirements.txt" ]; then
      echo "Scanning requirements.txt for vulnerabilities..."
      
      # Run safety check and capture output
      if [ -n "${SAFETY_API_KEY:-}" ]; then
        safety check --json --output safety-raw.json || SAFETY_EXIT_CODE=$?
      else
        safety check --json --output safety-raw.json --ignore-unpinned || SAFETY_EXIT_CODE=$?
      fi
      
      # Convert Safety JSON to GitLab security report format
      if [ -f "safety-raw.json" ] && [ -s "safety-raw.json" ]; then
        echo "Converting Safety report to GitLab format..."
        
        # Process each vulnerability from Safety report
        jq -r '.vulnerabilities[]? | @base64' safety-raw.json 2>/dev/null | while IFS= read -r vuln_b64; do
          if [ -n "$vuln_b64" ]; then
            vuln=$(echo "$vuln_b64" | base64 -d)
            
            # Extract vulnerability details
            package=$(echo "$vuln" | jq -r '.package_name // "unknown"')
            version=$(echo "$vuln" | jq -r '.analyzed_version // "unknown"')
            vuln_id=$(echo "$vuln" | jq -r '.vulnerability_id // "unknown"')
            advisory=$(echo "$vuln" | jq -r '.advisory // "No advisory available"')
            
            # Create GitLab vulnerability entry
            jq --null-input \
              --arg id "$vuln_id" \
              --arg package "$package" \
              --arg version "$version" \
              --arg advisory "$advisory" \
              --arg category "dependency_scanning" \
              --arg severity "Medium" \
              --arg confidence "High" \
              '{
                id: $id,
                category: $category,
                name: ("Vulnerability in " + $package),
                message: $advisory,
                description: $advisory,
                severity: $severity,
                confidence: $confidence,
                solution: "Upgrade to a fixed version",
                scanner: {
                  id: "safety",
                  name: "Safety"
                },
                location: {
                  file: "requirements.txt",
                  dependency: {
                    package: {
                      name: $package
                    },
                    version: $version
                  }
                },
                identifiers: [
                  {
                    type: "safety",
                    name: $id,
                    value: $id
                  }
                ]
              }' >> gl-vulnerabilities.json
          fi
        done
        
        # Merge vulnerabilities into main report
        if [ -f "gl-vulnerabilities.json" ]; then
          jq -s '.[0] as $report | .[1:] as $vulns | $report | .vulnerabilities = $vulns' gl-dependency-scanning-report.json gl-vulnerabilities.json > temp.json && mv temp.json gl-dependency-scanning-report.json
        fi
      fi
      
      # Keep original safety report as artifact
      cp safety-raw.json safety-report.json 2>/dev/null || echo '{"vulnerabilities": [], "scanned_packages": 0}' > safety-report.json
    else
      echo "No requirements.txt found for safety check"
      echo '{"vulnerabilities": [], "scanned_packages": 0}' > safety-report.json
    fi
    
    # Set end timestamp
    END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg end_time "$END_TIME" '.scan.end_time = $end_time' gl-dependency-scanning-report.json > temp.json && mv temp.json gl-dependency-scanning-report.json
    
    # Count vulnerabilities for summary
    vuln_count=$(jq '.vulnerabilities | length' gl-dependency-scanning-report.json)
    echo "Safety vulnerability check completed: $vuln_count vulnerabilities found"
    
  artifacts:
    reports:
      dependency_scanning: gl-dependency-scanning-report.json
    paths:
      - gl-dependency-scanning-report.json
      - safety-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

license-scanning:
  stage: security
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 10m
  before_script:
    - apt-get update && apt-get install -y git jq
    - pip install --upgrade pip
    - pip install --no-cache-dir pip-licenses
  script: |
    echo "Running license scanning with GitLab reporting..."
    
    # Initialize GitLab license scanning report
    cat > gl-license-scanning-report.json << 'EOF'
    {
      "version": "2.1",
      "licenses": [],
      "dependencies": [],
      "scan": {
        "analyzer": {
          "id": "pip-licenses",
          "name": "pip-licenses",
          "url": "https://pypi.org/project/pip-licenses/",
          "vendor": {
            "name": "pip-licenses"
          },
          "version": "latest"
        },
        "scanner": {
          "id": "pip-licenses",
          "name": "pip-licenses",
          "url": "https://pypi.org/project/pip-licenses/",
          "vendor": {
            "name": "pip-licenses"
          },
          "version": "latest"
        },
        "type": "license_scanning",
        "start_time": "",
        "end_time": "",
        "status": "success"
      }
    }
    EOF
    
    # Set scan timestamps
    START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg start_time "$START_TIME" '.scan.start_time = $start_time' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
    
    if [ -f "requirements.txt" ]; then
      echo "Installing dependencies and scanning licenses..."
      
      # Install dependencies from requirements.txt
      pip install -r requirements.txt || echo "Some dependencies failed to install"
      
      # Generate license report
      pip-licenses --format=json --output-file=pip-licenses-raw.json || echo "License scanning completed with warnings"
      
      # Convert pip-licenses output to GitLab format
      if [ -f "pip-licenses-raw.json" ] && [ -s "pip-licenses-raw.json" ]; then
        echo "Converting license report to GitLab format..."
        
        # Process each dependency
        jq -r '.[]? | @base64' pip-licenses-raw.json 2>/dev/null | while IFS= read -r dep_b64; do
          if [ -n "$dep_b64" ]; then
            dep=$(echo "$dep_b64" | base64 -d)
            
            # Extract dependency details
            name=$(echo "$dep" | jq -r '.Name // "unknown"')
            version=$(echo "$dep" | jq -r '.Version // "unknown"')
            license_name=$(echo "$dep" | jq -r '.License // "Unknown"')
            
            # Classify license risk level
            case "$license_name" in
              "MIT"|"Apache 2.0"|"Apache Software License"|"BSD"|"BSD License"|"3-Clause BSD"|"2-Clause BSD")
                classification="allowed"
                ;;
              "GPL"*|"AGPL"*|"LGPL"*)
                classification="denied"
                ;;
              "Unknown"|"UNKNOWN"|"")
                classification="unclassified"
                ;;
              *)
                classification="unclassified"
                ;;
            esac
            
            # Create license entry
            jq --null-input \
              --arg name "$license_name" \
              --arg classification "$classification" \
              '{
                key: $name,
                name: $name,
                spdx_identifier: $name,
                classification: $classification
              }' >> gl-licenses-temp.json
            
            # Create dependency entry
            jq --null-input \
              --arg name "$name" \
              --arg version "$version" \
              --arg license "$license_name" \
              --arg classification "$classification" \
              '{
                name: $name,
                version: $version,
                package_manager: "pip",
                path: "requirements.txt",
                licenses: [
                  {
                    key: $license,
                    name: $license,
                    spdx_identifier: $license
                  }
                ],
                classification: $classification
              }' >> gl-dependencies-temp.json
          fi
        done
        
        # Merge unique licenses and dependencies into main report
        if [ -f "gl-licenses-temp.json" ]; then
          jq -s 'unique_by(.key)' gl-licenses-temp.json > gl-licenses.json
          jq --slurpfile licenses gl-licenses.json '.licenses = $licenses[0]' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
        fi
        
        if [ -f "gl-dependencies-temp.json" ]; then
          jq -s 'unique_by(.name)' gl-dependencies-temp.json > gl-dependencies.json
          jq --slurpfile deps gl-dependencies.json '.dependencies = $deps[0]' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
        fi
      fi
      
      # Keep original pip-licenses report as artifact
      cp pip-licenses-raw.json pip-licenses-report.json 2>/dev/null || echo '[]' > pip-licenses-report.json
    else
      echo "No requirements.txt found for license scanning"
      echo '[]' > pip-licenses-report.json
    fi
    
    # Set end timestamp
    END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg end_time "$END_TIME" '.scan.end_time = $end_time' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
    
    # Count licenses and dependencies for summary
    license_count=$(jq '.licenses | length' gl-license-scanning-report.json)
    dep_count=$(jq '.dependencies | length' gl-license-scanning-report.json)
    denied_count=$(jq '[.dependencies[] | select(.classification == "denied")] | length' gl-license-scanning-report.json)
    
    echo "License scanning completed: $dep_count dependencies, $license_count unique licenses, $denied_count denied licenses"
    
    if [ "$denied_count" -gt 0 ]; then
      echo "WARNING: Found dependencies with denied licenses - review required"
    fi
    
  artifacts:
    reports:
      license_scanning: gl-license-scanning-report.json
    paths:
      - gl-license-scanning-report.json
      - pip-licenses-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# =============================================================================
# BUILD STAGE
# =============================================================================

build-image-shell:
  stage: build
  tags:
    - trakbridge-cd
  timeout: 45m
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
  before_script: |
    echo "Using host Docker daemon..."
    docker --version
    echo "Authenticating with GitLab Container Registry..."

    if [ -z "${CI_REGISTRY_USER}" ] || [ -z "${CI_REGISTRY_PASSWORD}" ]; then
      echo "Error: CI_REGISTRY_USER and CI_REGISTRY_PASSWORD must be set"
      exit 1
    fi
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"

    echo "Git information:"
    git --version
    git log --oneline -5 || echo "No git log available"
    git describe --tags --long --dirty || echo "No git describe available"
  script: |
    echo "Building container image with host Docker..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Tag: $CI_COMMIT_TAG"
    echo "Ref name: $CI_COMMIT_REF_NAME"

    # Set proper version for setuptools_scm
    if [ -n "$CI_COMMIT_TAG" ]; then
      export SETUPTOOLS_SCM_PRETEND_VERSION="$CI_COMMIT_TAG"
      echo "Using tag version: $CI_COMMIT_TAG"
    else
      export SETUPTOOLS_SCM_PRETEND_VERSION="0.1.0.dev0+g$CI_COMMIT_SHORT_SHA"
      echo "Using dev version: 0.1.0.dev0+g$CI_COMMIT_SHORT_SHA"
    fi

    # Build with better error handling
    if ! DOCKER_BUILDKIT=1 docker build \
      --target=production \
      --tag "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA" \
      --tag "$CI_REGISTRY_IMAGE:dev" \
      --label "org.opencontainers.image.source=$CI_PROJECT_URL" \
      --label "org.opencontainers.image.revision=$CI_COMMIT_SHA" \
      --label "org.opencontainers.image.created=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      --label "org.opencontainers.image.version=$CI_COMMIT_REF_NAME" \
      --label "org.opencontainers.image.title=$APP_NAME" \
      --build-arg SETUPTOOLS_SCM_PRETEND_VERSION="$SETUPTOOLS_SCM_PRETEND_VERSION" \
      --file Dockerfile \
      . ; then
      echo "Docker build failed"
      exit 1
    fi
    echo "Pushing dev image to GitLab Container Registry..."
    docker push "$CI_REGISTRY_IMAGE:dev"
    echo "Container build and push completed for dev image"
    echo "Pushed to: $CI_REGISTRY_IMAGE:dev"
  rules:
    - if: '$CI_COMMIT_TAG != null'
      when: never
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null

build-tagged-image-shell:
  stage: build
  tags:
    - trakbridge-cd
  timeout: 45m
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
  before_script: |
    echo "Using host Docker daemon..."
    docker --version
    echo "Authenticating with container registry..."

    if [ -z "${DOCKERHUB_USERNAME}" ] || [ -z "${DOCKERHUB_TOKEN}" ]; then
      echo "Error: DOCKERHUB_USERNAME and DOCKERHUB_TOKEN must be set"
      exit 1
    fi
    echo "${DOCKERHUB_TOKEN}" | docker login --username "${DOCKERHUB_USERNAME}" --password-stdin "${REGISTRY}"

    echo "Git information:"
    git --version
    git log --oneline -5 || echo "No git log available"
    git describe --tags --long --dirty || echo "No git describe available"
  script: |
    echo "Building tagged container image with host Docker..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Tag: $CI_COMMIT_TAG"
    echo "Ref name: $CI_COMMIT_REF_NAME"

    # For tagged builds, use the tag as version
    export SETUPTOOLS_SCM_PRETEND_VERSION="$CI_COMMIT_TAG"
    echo "Using tag version: $CI_COMMIT_TAG"

    if ! DOCKER_BUILDKIT=1 docker build \
      --target=production \
      --tag "$IMAGE_NAME:$CI_COMMIT_TAG" \
      --tag "$IMAGE_NAME:latest" \
      --label "org.opencontainers.image.source=$CI_PROJECT_URL" \
      --label "org.opencontainers.image.revision=$CI_COMMIT_SHA" \
      --label "org.opencontainers.image.created=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      --label "org.opencontainers.image.version=$CI_COMMIT_TAG" \
      --label "org.opencontainers.image.title=$APP_NAME" \
      --build-arg SETUPTOOLS_SCM_PRETEND_VERSION="$CI_COMMIT_TAG" \
      --file Dockerfile \
      . ; then
      echo "Docker build failed"
      exit 1
    fi
    echo "Pushing tagged images..."
    docker push "$IMAGE_NAME:$CI_COMMIT_TAG"
    docker push "$IMAGE_NAME:latest"
    echo "Tagged container build and push completed"
  rules:
    - if: $CI_COMMIT_TAG

# Feature branch build for development testing
build-feature-branch-shell:
  stage: build
  tags:
    - trakbridge-cd
  timeout: 45m
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
  before_script: |
    echo "Using host Docker daemon..."
    docker --version
    echo "Authenticating with GitLab Container Registry..."

    if [ -z "${CI_REGISTRY_USER}" ] || [ -z "${CI_REGISTRY_PASSWORD}" ]; then
      echo "Error: CI_REGISTRY_USER and CI_REGISTRY_PASSWORD must be set"
      exit 1
    fi
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"

    echo "Git information:"
    git --version
    git log --oneline -5 || echo "No git log available"
    git describe --tags --long --dirty || echo "No git describe available"
  script: |
    echo "Building feature branch container image with host Docker..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Ref name: $CI_COMMIT_REF_NAME"
    echo "Ref slug: $CI_COMMIT_REF_SLUG"

    # Set proper version for setuptools_scm for feature branches
    export SETUPTOOLS_SCM_PRETEND_VERSION="0.1.0.dev0+$CI_COMMIT_REF_SLUG.$CI_COMMIT_SHORT_SHA"
    echo "Using feature branch version: $SETUPTOOLS_SCM_PRETEND_VERSION"

    # Build with branch-specific tagging
    BRANCH_TAG="${CI_COMMIT_REF_SLUG}"
    
    if ! DOCKER_BUILDKIT=1 docker build \
      --target=production \
      --tag "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA" \
      --tag "$CI_REGISTRY_IMAGE:$BRANCH_TAG" \
      --label "org.opencontainers.image.source=$CI_PROJECT_URL" \
      --label "org.opencontainers.image.revision=$CI_COMMIT_SHA" \
      --label "org.opencontainers.image.created=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      --label "org.opencontainers.image.version=$CI_COMMIT_REF_NAME" \
      --label "org.opencontainers.image.title=$APP_NAME" \
      --label "org.opencontainers.image.branch=$CI_COMMIT_BRANCH" \
      --build-arg SETUPTOOLS_SCM_PRETEND_VERSION="$SETUPTOOLS_SCM_PRETEND_VERSION" \
      --file Dockerfile \
      . ; then
      echo "Docker build failed"
      exit 1
    fi
    echo "Pushing feature branch image to GitLab Container Registry..."
    docker push "$CI_REGISTRY_IMAGE:$BRANCH_TAG"
    echo "Feature branch container build and push completed for $BRANCH_TAG"
    echo "Pushed to: $CI_REGISTRY_IMAGE:$BRANCH_TAG"
  after_script: |
    # Clean up any root-owned directories created by Docker build
    echo "Cleaning up Docker build directory permissions..."
    sudo find . -type d -name "data" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "logs" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "build" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "dist" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "__pycache__" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -name "*.egg-info" -type d -exec chmod 755 {} \; 2>/dev/null || true
    sudo chown -R gitlab-runner:gitlab-runner . 2>/dev/null || true
    echo "Permission cleanup completed"
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: on_success

# =============================================================================
# DEPLOYMENT STAGE - Environment-specific Deployments
# =============================================================================

# Development deployment
deploy-development:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 30m
  
  environment:
    name: development
    url: http://localhost:5000
    deployment_tier: development
  
  variables:
    DEPLOY_ENV: "development"
    APP_VERSION: "${CI_COMMIT_REF_NAME}-${CI_COMMIT_SHORT_SHA}"
    DOCKER_TLS_CERTDIR: ""
  
  before_script: |
    # Authenticate with GitLab Container Registry
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"
  
  script: |
    echo "Deploying to development environment..."
    
    # Use the built development image (already available locally from build-image-shell)
    echo "Using local development image: $CI_REGISTRY_IMAGE:dev"
    if docker image inspect $CI_REGISTRY_IMAGE:dev > /dev/null 2>&1; then
      # Tag it with the name the deploy script expects for --environment development
      docker tag $CI_REGISTRY_IMAGE:dev $CI_REGISTRY_IMAGE:development
      echo "Successfully tagged local development image as $CI_REGISTRY_IMAGE:development"
    else
      echo "ERROR: Local development image not found: $CI_REGISTRY_IMAGE:dev"
      echo "This usually means the build-image-shell job failed or didn't run"
      echo "Available images:"
      docker images | grep "$CI_REGISTRY_IMAGE" || echo "No images found with registry prefix"
      exit 1
    fi
    
    # Export GitLab CI variables for Docker Compose
    echo "Exporting GitLab CI variables for Docker Compose..."
    export LDAP_SERVER="${LDAP_SERVER:-ldap://your-ad-server.company.com}"
    export LDAP_ENABLED="${LDAP_ENABLED:-false}"
    export LDAP_PORT="${LDAP_PORT:-389}"
    export LDAP_USE_SSL="${LDAP_USE_SSL:-false}"
    export LDAP_USE_TLS="${LDAP_USE_TLS:-false}"
    export LDAP_VALIDATE_CERT="${LDAP_VALIDATE_CERT:-false}"
    export LDAP_BIND_DN="${LDAP_BIND_DN:-CN=trakbridge,OU=Service Accounts,DC=company,DC=com}"
    export LDAP_BIND_PASSWORD="${LDAP_BIND_PASSWORD:-default-ldap-password}"
    export LDAP_USER_SEARCH_BASE="${LDAP_USER_SEARCH_BASE:-OU=Users,DC=company,DC=com}"
    export LDAP_USER_SEARCH_FILTER="${LDAP_USER_SEARCH_FILTER}"
    export LDAP_GROUP_SEARCH_BASE="${LDAP_GROUP_SEARCH_BASE:-OU=Groups,DC=company,DC=com}"
    export LDAP_GROUP_SEARCH_FILTER="${LDAP_GROUP_SEARCH_FILTER}"
    export LDAP_ADMIN_GROUP="${LDAP_ADMIN_GROUP:-CN=TrakBridge-Admins,OU=Groups,DC=company,DC=com}"
    export LDAP_OPERATOR_GROUP="${LDAP_OPERATOR_GROUP:-CN=TrakBridge-Operators,OU=Groups,DC=company,DC=com}"
    export LDAP_USER_GROUP="${LDAP_USER_GROUP:-CN=TrakBridge-Users,OU=Groups,DC=company,DC=com}"
    export LDAP_DEFAULT_ROLE="${LDAP_DEFAULT_ROLE:-user}"
    export LDAP_CONNECTION_TIMEOUT="${LDAP_CONNECTION_TIMEOUT:-10}"
    export LDAP_RESPONSE_TIMEOUT="${LDAP_RESPONSE_TIMEOUT:-30}"
    
    # OIDC/SSO Settings
    export OIDC_ENABLED="${OIDC_ENABLED:-false}"
    export OIDC_ISSUER="${OIDC_ISSUER:-https://your-identity-provider.com}"
    export OIDC_CLIENT_ID="${OIDC_CLIENT_ID:-trakbridge-client}"
    export OIDC_CLIENT_SECRET="${OIDC_CLIENT_SECRET:-default-oidc-secret}"
    export OIDC_REDIRECT_URI="${OIDC_REDIRECT_URI:-http://localhost:5000/auth/oidc/callback}"
    export OIDC_VERIFY_SIGNATURE="${OIDC_VERIFY_SIGNATURE:-false}"
    export OIDC_VERIFY_AUDIENCE="${OIDC_VERIFY_AUDIENCE:-false}"
    export OIDC_VERIFY_ISSUER="${OIDC_VERIFY_ISSUER:-false}"
    export OIDC_ADMIN_GROUP="${OIDC_ADMIN_GROUP:-trakbridge-admins}"
    export OIDC_OPERATOR_GROUP="${OIDC_OPERATOR_GROUP:-trakbridge-operators}"
    export OIDC_USER_GROUP="${OIDC_USER_GROUP:-trakbridge-users}"
    export OIDC_DEFAULT_ROLE="${OIDC_DEFAULT_ROLE:-user}"
    
    echo "LDAP_SERVER will be set to: $LDAP_SERVER"
    echo "LDAP_BIND_PASSWORD length: ${#LDAP_BIND_PASSWORD}"
    echo "LDAP_BIND_PASSWORD first 10 chars: ${LDAP_BIND_PASSWORD:0:10}..."
    
    # Export dynamic user variables for Docker runtime user creation
    export USER_ID=${USER_ID:-$(id -u)}
    export GROUP_ID=${GROUP_ID:-$(id -g)}
    
    # Set the application port to match docker-compose-dev.yml
    export APP_PORT=5060
    
    # Don't override CI_REGISTRY_IMAGE - let it use the GitLab registry name
    # The deploy script will set IMAGE_TAG="development" for --environment development
    
    # Clean up any existing containers on port 5060 to prevent port conflicts
    echo "Cleaning up any existing containers using port 5060..."
    docker ps -q --filter "publish=5060" | xargs -r docker stop || echo "No containers using port 5050"
    docker ps -aq --filter "publish=5060" | xargs -r docker rm || echo "No stopped containers to remove"
    
    # Also check for containers with the default name
    docker ps -q --filter "name=trakbridge" | xargs -r docker stop || echo "No trakbridge containers running"
    docker ps -aq --filter "name=trakbridge" | xargs -r docker rm || echo "No trakbridge containers to remove"
    
    # Set up development environment using deployment script
    chmod +x scripts/deploy.sh

    scripts/deploy.sh \
      --environment development \
      --action deploy \
      --profiles postgres \
      --timeout 300 \
      --use-prebuilt \
      --skip-health-check \
      --verbose
    
    # Debug: Check environment variables inside the container
    echo "=== CONTAINER ENVIRONMENT DEBUG ==="
    docker exec trakbridge env | grep LDAP || echo "No LDAP environment variables found"
    echo "Container LDAP_BIND_PASSWORD length:"
    docker exec trakbridge sh -c 'echo ${#LDAP_BIND_PASSWORD}' || echo "LDAP_BIND_PASSWORD not set in container"
    echo "=== END CONTAINER DEBUG ==="
    
    echo "Development deployment completed"
    echo "Application URL: http://localhost:5060"
    echo "Default login: admin / TrakBridge-Setup-2025!"
  
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "web" && $DEPLOY_ENVIRONMENT == "development"
  
  dependencies:
    - build-image-shell
  
  after_script:
    - |
      # Generate deployment health report
      echo "Generating deployment health report..."
      
      # Create deployment report
      cat > deployment-health-report.json << EOF
      {
        "deployment": {
          "environment": "development",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "status": "success",
          "url": "http://localhost:5000",
          "version": "${CI_COMMIT_SHA}",
          "branch": "${CI_COMMIT_BRANCH}"
        },
        "health_checks": [],
        "metrics": {
          "deployment_duration": "${SECONDS:-0}",
          "services_count": 0,
          "containers_running": 0
        }
      }
      EOF
      
      # Test application health
      if curl -f -s http://localhost:5000/api/health > health-response.json 2>/dev/null; then
        echo "âœ… Health check passed"
        jq '.health_checks += [{"name": "api_health", "status": "pass", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      else
        echo "âŒ Health check failed"
        jq '.health_checks += [{"name": "api_health", "status": "fail", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
        jq '.deployment.status = "failed"' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
        
        # Add debug logs for failed health check
        echo "=== DEBUG: Container logs after health check failure ==="
        docker logs trakbridge --tail=30 || echo "Could not get app container logs"
        echo "=== END DEBUG LOGS ==="
      fi
      
      # Count running containers
      if command -v docker > /dev/null 2>&1; then
        running_containers=$(docker ps --filter "label=com.docker.compose.project=trakbridge" --format "table {{.Names}}" | tail -n +2 | wc -l)
        jq --argjson count "$running_containers" '.metrics.containers_running = $count' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      fi
      
      echo "Deployment health report generated"

  artifacts:
    paths:
      - deployment-health-report.json
      - health-response.json
    expire_in: 1 week
    when: always

# Staging deployment
deploy-staging:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 30m
  
  environment:
    name: staging
    url: http://localhost
    deployment_tier: staging
  
  variables:
    DEPLOY_ENV: "staging"
    APP_VERSION: "${CI_COMMIT_TAG:-${CI_COMMIT_REF_NAME}-${CI_COMMIT_SHORT_SHA}}"
    DOCKER_TLS_CERTDIR: ""
  
  before_script: |
    # Authenticate with GitLab Container Registry
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"
  
  script: |
    echo "ðŸ”„ Deploying to staging environment..."
    
    # Pull the built image from GitLab Container Registry
    echo "Pulling from GitLab Container Registry: $CI_REGISTRY_IMAGE:${CI_COMMIT_REF_NAME}"
    docker pull $CI_REGISTRY_IMAGE:${CI_COMMIT_REF_NAME} || docker pull $CI_REGISTRY_IMAGE:dev
    docker tag $CI_REGISTRY_IMAGE:${CI_COMMIT_REF_NAME} trakbridge:staging-latest || docker tag $CI_REGISTRY_IMAGE:dev trakbridge:staging-latest
    
    # Export GitLab CI variables for Docker Compose
    echo "Exporting GitLab CI variables for Docker Compose..."
    export LDAP_SERVER="${LDAP_SERVER:-ldap://your-ad-server.company.com}"
    export LDAP_ENABLED="${LDAP_ENABLED:-false}"
    export LDAP_PORT="${LDAP_PORT:-389}"
    export LDAP_USE_SSL="${LDAP_USE_SSL:-false}"
    export LDAP_USE_TLS="${LDAP_USE_TLS:-false}"
    export LDAP_VALIDATE_CERT="${LDAP_VALIDATE_CERT:-false}"
    export LDAP_BIND_DN="${LDAP_BIND_DN:-CN=trakbridge,OU=Service Accounts,DC=company,DC=com}"
    export LDAP_BIND_PASSWORD="${LDAP_BIND_PASSWORD:-default-ldap-password}"
    export LDAP_USER_SEARCH_BASE="${LDAP_USER_SEARCH_BASE:-OU=Users,DC=company,DC=com}"
    export LDAP_USER_SEARCH_FILTER="${LDAP_USER_SEARCH_FILTER}"
    export LDAP_GROUP_SEARCH_BASE="${LDAP_GROUP_SEARCH_BASE:-OU=Groups,DC=company,DC=com}"
    export LDAP_GROUP_SEARCH_FILTER="${LDAP_GROUP_SEARCH_FILTER}"
    export LDAP_ADMIN_GROUP="${LDAP_ADMIN_GROUP:-CN=TrakBridge-Admins,OU=Groups,DC=company,DC=com}"
    export LDAP_OPERATOR_GROUP="${LDAP_OPERATOR_GROUP:-CN=TrakBridge-Operators,OU=Groups,DC=company,DC=com}"
    export LDAP_USER_GROUP="${LDAP_USER_GROUP:-CN=TrakBridge-Users,OU=Groups,DC=company,DC=com}"
    export LDAP_DEFAULT_ROLE="${LDAP_DEFAULT_ROLE:-user}"
    export LDAP_CONNECTION_TIMEOUT="${LDAP_CONNECTION_TIMEOUT:-10}"
    export LDAP_RESPONSE_TIMEOUT="${LDAP_RESPONSE_TIMEOUT:-30}"
    
    # OIDC/SSO Settings
    export OIDC_ENABLED="${OIDC_ENABLED:-false}"
    export OIDC_ISSUER="${OIDC_ISSUER:-https://your-identity-provider.com}"
    export OIDC_CLIENT_ID="${OIDC_CLIENT_ID:-trakbridge-client}"
    export OIDC_CLIENT_SECRET="${OIDC_CLIENT_SECRET:-default-oidc-secret}"
    export OIDC_REDIRECT_URI="${OIDC_REDIRECT_URI:-http://localhost:5000/auth/oidc/callback}"
    export OIDC_VERIFY_SIGNATURE="${OIDC_VERIFY_SIGNATURE:-false}"
    export OIDC_VERIFY_AUDIENCE="${OIDC_VERIFY_AUDIENCE:-false}"
    export OIDC_VERIFY_ISSUER="${OIDC_VERIFY_ISSUER:-false}"
    export OIDC_ADMIN_GROUP="${OIDC_ADMIN_GROUP:-trakbridge-admins}"
    export OIDC_OPERATOR_GROUP="${OIDC_OPERATOR_GROUP:-trakbridge-operators}"
    export OIDC_USER_GROUP="${OIDC_USER_GROUP:-trakbridge-users}"
    export OIDC_DEFAULT_ROLE="${OIDC_DEFAULT_ROLE:-user}"
    
    echo "LDAP_SERVER will be set to: $LDAP_SERVER"
    echo "LDAP_BIND_PASSWORD length: ${#LDAP_BIND_PASSWORD}"
    echo "LDAP_BIND_PASSWORD first 10 chars: ${LDAP_BIND_PASSWORD:0:10}..."
    
    # Set up staging environment
    chmod +x scripts/deploy.sh

    scripts/deploy.sh \
      --environment staging \
      --action deploy \
      --profiles "postgres,nginx" \
      --timeout 300 \
      --use-prebuilt \
      --skip-health-check \
      --verbose
    
    # Run staging validation tests
    echo "Running staging validation tests..."
    chmod +x scripts/health-check.sh
    scripts/health-check.sh --url http://localhost --performance --verbose
    
    echo "Staging deployment completed"
    echo "Application URL: http://localhost"
  
  rules:
    - if: $CI_PIPELINE_SOURCE == "web" && $DEPLOY_ENVIRONMENT == "staging"
  
  # Manual approval required for staging
  when: manual
  
  dependencies:
    - build-image-shell
  
  after_script:
    - |
      # Generate deployment health report for staging
      echo "Generating staging deployment health report..."
      
      cat > deployment-health-report.json << EOF
      {
        "deployment": {
          "environment": "staging",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "status": "success",
          "url": "http://localhost",
          "version": "${CI_COMMIT_SHA}",
          "branch": "${CI_COMMIT_BRANCH}"
        },
        "health_checks": [],
        "metrics": {
          "deployment_duration": "${SECONDS:-0}",
          "containers_running": 0
        }
      }
      EOF
      
      # Test application health through nginx
      if curl -f -s http://localhost/api/health > health-response.json 2>/dev/null; then
        echo "Staging health check passed"
        jq '.health_checks += [{"name": "api_health_nginx", "status": "pass", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      else
        echo "Staging health check failed"
        jq '.health_checks += [{"name": "api_health_nginx", "status": "fail", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
        jq '.deployment.status = "failed"' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      fi

  artifacts:
    paths:
      - deployment-health-report.json
      - health-response.json
    expire_in: 1 week
    when: always


# Feature branch dynamic environment deployment
deploy-feature-branch:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 30m
  
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    url: http://localhost:5001
    deployment_tier: development
    auto_stop_in: 1 week
    on_stop: stop-feature-branch
  
  variables:
    DEPLOY_ENV: "feature"
    APP_VERSION: "${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}"
    DOCKER_TLS_CERTDIR: ""
  
  before_script: |
    # Authenticate with GitLab Container Registry for pulling
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"
    
    # Generate dynamic port based on branch hash (5001-5099 range)
    export DYNAMIC_PORT=$((5001 + (0x$(echo -n "$CI_COMMIT_REF_SLUG" | sha256sum | head -c 2) % 99)))
    echo "Deploying feature branch to dynamic environment..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Environment: review/$CI_COMMIT_REF_SLUG"
    echo "Dynamic Port: $DYNAMIC_PORT"
    
    # Update GitLab environment URL with actual dynamic port
    if [ -n "$CI_JOB_TOKEN" ] && [ -n "$CI_PROJECT_ID" ]; then
      ENVIRONMENT_URL="http://localhost:$DYNAMIC_PORT"
      echo "Updating GitLab environment URL to: $ENVIRONMENT_URL"
      
      curl -s --request PUT \
        --header "JOB-TOKEN: $CI_JOB_TOKEN" \
        --header "Content-Type: application/json" \
        --data "{\"external_url\": \"$ENVIRONMENT_URL\"}" \
        "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/environments/$(echo "review/$CI_COMMIT_REF_SLUG" | sed 's/\//%2F/g')" \
        || echo "Failed to update environment URL (this is non-critical)"
    fi
  
  script: |
    # Debug: Show current environment and available images
    echo "=== DEPLOYMENT DEBUG INFO ==="
    echo "CI_REGISTRY_IMAGE: ${CI_REGISTRY_IMAGE:-'not set'}"
    echo "IMAGE_NAME: ${IMAGE_NAME:-'not set'}"
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Commit SHA: $CI_COMMIT_SHA"
    echo "============================="
    
    # Use the built feature branch image (already available locally)
    BRANCH_TAG="${CI_COMMIT_REF_SLUG}"
    
    echo "Using local image: $CI_REGISTRY_IMAGE:$BRANCH_TAG"
    if docker image inspect $CI_REGISTRY_IMAGE:$BRANCH_TAG > /dev/null 2>&1; then
      docker tag $CI_REGISTRY_IMAGE:$BRANCH_TAG trakbridge:$BRANCH_TAG-latest
      echo "Successfully tagged local image"
    else
      echo "ERROR: Local image not found: $CI_REGISTRY_IMAGE:$BRANCH_TAG"
      echo "This usually means the build-feature-branch-shell job failed or didn't run"
      echo "Available images:"
      docker images | grep "$CI_REGISTRY_IMAGE"
      exit 1
    fi
    
    # Debug: Check current directory and file structure
    echo "=== FILE SYSTEM DEBUG ==="
    pwd
    echo "Contents of current directory:"
    ls -la
    echo "Looking for scripts directory:"
    ls -la scripts/ || echo "scripts directory not found"
    echo "Checking if deploy.sh exists:"
    find . -name "deploy.sh" -type f || echo "deploy.sh not found anywhere"
    echo "=========================="
    
    # Check if we need to use absolute path or if file exists
    if [ -f "./scripts/deploy.sh" ]; then
      chmod +x ./scripts/deploy.sh
      DEPLOY_SCRIPT="./scripts/deploy.sh"
    elif [ -f "$CI_PROJECT_DIR/scripts/deploy.sh" ]; then
      chmod +x "$CI_PROJECT_DIR/scripts/deploy.sh"
      DEPLOY_SCRIPT="$CI_PROJECT_DIR/scripts/deploy.sh"
    else
      echo "ERROR: scripts/deploy.sh not found in expected locations"
      echo "Checked:"
      echo "  - ./scripts/deploy.sh"
      echo "  - $CI_PROJECT_DIR/scripts/deploy.sh"
      exit 1
    fi
    
    echo "Using deploy script: $DEPLOY_SCRIPT"

    # Set environment variables for feature branch deployment
    export FEATURE_BRANCH_PORT=$DYNAMIC_PORT
    export FEATURE_BRANCH_NAME="$CI_COMMIT_REF_SLUG"
    export COMPOSE_PROJECT_NAME="trakbridge-$CI_COMMIT_REF_SLUG"
    
    # Export dynamic user variables for Docker runtime user creation
    export USER_ID=${USER_ID:-$(id -u)}
    export GROUP_ID=${GROUP_ID:-$(id -g)}
    
    # Export GitLab CI variables for Docker Compose
    echo "Exporting GitLab CI variables for Docker Compose..."
    export LDAP_SERVER="${LDAP_SERVER:-ldap://your-ad-server.company.com}"
    export LDAP_ENABLED="${LDAP_ENABLED:-false}"
    export LDAP_PORT="${LDAP_PORT:-389}"
    export LDAP_USE_SSL="${LDAP_USE_SSL:-false}"
    export LDAP_USE_TLS="${LDAP_USE_TLS:-false}"
    export LDAP_VALIDATE_CERT="${LDAP_VALIDATE_CERT:-false}"
    export LDAP_BIND_DN="${LDAP_BIND_DN:-CN=trakbridge,OU=Service Accounts,DC=company,DC=com}"
    export LDAP_BIND_PASSWORD="${LDAP_BIND_PASSWORD:-default-ldap-password}"
    export LDAP_USER_SEARCH_BASE="${LDAP_USER_SEARCH_BASE:-OU=Users,DC=company,DC=com}"
    export LDAP_USER_SEARCH_FILTER="${LDAP_USER_SEARCH_FILTER}"
    export LDAP_GROUP_SEARCH_BASE="${LDAP_GROUP_SEARCH_BASE:-OU=Groups,DC=company,DC=com}"
    export LDAP_GROUP_SEARCH_FILTER="${LDAP_GROUP_SEARCH_FILTER}"
    export LDAP_ADMIN_GROUP="${LDAP_ADMIN_GROUP:-CN=TrakBridge-Admins,OU=Groups,DC=company,DC=com}"
    export LDAP_OPERATOR_GROUP="${LDAP_OPERATOR_GROUP:-CN=TrakBridge-Operators,OU=Groups,DC=company,DC=com}"
    export LDAP_USER_GROUP="${LDAP_USER_GROUP:-CN=TrakBridge-Users,OU=Groups,DC=company,DC=com}"
    export LDAP_DEFAULT_ROLE="${LDAP_DEFAULT_ROLE:-user}"
    export LDAP_CONNECTION_TIMEOUT="${LDAP_CONNECTION_TIMEOUT:-10}"
    export LDAP_RESPONSE_TIMEOUT="${LDAP_RESPONSE_TIMEOUT:-30}"
    
    # OIDC/SSO Settings  
    export OIDC_ENABLED="${OIDC_ENABLED:-false}"
    export OIDC_ISSUER="${OIDC_ISSUER:-https://your-identity-provider.com}"
    export OIDC_CLIENT_ID="${OIDC_CLIENT_ID:-trakbridge-client}"
    export OIDC_CLIENT_SECRET="${OIDC_CLIENT_SECRET:-default-oidc-secret}"
    export OIDC_REDIRECT_URI="${OIDC_REDIRECT_URI:-http://localhost:5000/auth/oidc/callback}"
    export OIDC_VERIFY_SIGNATURE="${OIDC_VERIFY_SIGNATURE:-false}"
    export OIDC_VERIFY_AUDIENCE="${OIDC_VERIFY_AUDIENCE:-false}"
    export OIDC_VERIFY_ISSUER="${OIDC_VERIFY_ISSUER:-false}"
    export OIDC_ADMIN_GROUP="${OIDC_ADMIN_GROUP:-trakbridge-admins}"
    export OIDC_OPERATOR_GROUP="${OIDC_OPERATOR_GROUP:-trakbridge-operators}"
    export OIDC_USER_GROUP="${OIDC_USER_GROUP:-trakbridge-users}"
    export OIDC_DEFAULT_ROLE="${OIDC_DEFAULT_ROLE:-user}"
    
    echo "LDAP_SERVER will be set to: $LDAP_SERVER"
    echo "LDAP_BIND_PASSWORD length: ${#LDAP_BIND_PASSWORD}"
    echo "LDAP_BIND_PASSWORD first 10 chars: ${LDAP_BIND_PASSWORD:0:10}..."
    
    $DEPLOY_SCRIPT \
      --environment feature \
      --action deploy \
      --port $DYNAMIC_PORT \
      --profiles postgres \
      --timeout 300 \
      --branch "$CI_COMMIT_REF_SLUG" \
      --use-prebuilt \
      --skip-health-check \
      --verbose
    
    # Health check for the dynamic environment using Docker health status
    echo "Checking Docker container health status..."
    
    # Wait for container to be healthy (Docker's built-in health check)
    timeout 120 bash -c "
      while true; do
        container_health=\$(docker inspect --format='{{.State.Health.Status}}' ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} 2>/dev/null || echo 'none')
        echo \"Container health status: \$container_health\"
        
        case \$container_health in
          'healthy')
            echo 'Container is healthy!'
            exit 0
            ;;
          'unhealthy')
            echo 'Container is unhealthy!'
            exit 1
            ;;
          'starting'|'none')
            echo 'Container is still starting, waiting...'
            sleep 10
            ;;
          *)
            echo 'Unknown health status, waiting...'
            sleep 10
            ;;
        esac
      done
    "
    
    # Additional verification with direct API call
    if curl -f http://localhost:$DYNAMIC_PORT/api/health; then
      echo "Feature branch deployment verified successfully"
    else
      echo "Feature branch deployment verification failed"
      echo "=== CONTAINER LOGS FOR DEBUGGING ==="
      echo "--- Application Container Logs ---"
      docker logs ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} --tail=50 || echo "Could not get app container logs"
      echo "--- PostgreSQL Container Logs ---"
      docker logs ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG}-postgres --tail=20 || echo "Could not get postgres container logs"
      echo "--- Container Status ---"
      docker ps --filter "name=${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG}" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
      echo "=== END CONTAINER LOGS ==="
      exit 1
    fi
    
    # Debug: Check environment variables inside the container
    echo "=== CONTAINER ENVIRONMENT DEBUG ==="
    docker exec ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} env | grep LDAP || echo "No LDAP environment variables found"
    echo "Container LDAP_BIND_PASSWORD length:"
    docker exec ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} sh -c 'echo ${#LDAP_BIND_PASSWORD}' || echo "LDAP_BIND_PASSWORD not set in container"
    echo "=== END CONTAINER DEBUG ==="
    
    echo "Feature branch deployment completed"
    echo "Feature Branch URL: http://localhost:$DYNAMIC_PORT"
    echo "Default login: admin / TrakBridge-Setup-2025!"
    echo "Environment: review/$CI_COMMIT_REF_SLUG"
    
    # Generate feature branch deployment health report
    cat > deployment-health-report.json << EOF
    {
      "deployment": {
        "environment": "feature",
        "feature_branch": "$CI_COMMIT_REF_SLUG",
        "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
        "status": "success",
        "url": "http://localhost:$DYNAMIC_PORT",
        "port": $DYNAMIC_PORT,
        "version": "${CI_COMMIT_SHA}",
        "branch": "${CI_COMMIT_BRANCH}"
      },
      "health_checks": [],
      "metrics": {
        "deployment_duration": "${SECONDS:-0}",
        "containers_running": 0
      }
    }
    EOF
    
    # The health check was already performed above, record the result
    if curl -f http://localhost:$DYNAMIC_PORT/api/health > health-response.json 2>/dev/null; then
      jq '.health_checks += [{"name": "feature_api_health", "status": "pass", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "port": '$DYNAMIC_PORT'}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
    else
      jq '.health_checks += [{"name": "feature_api_health", "status": "fail", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "port": '$DYNAMIC_PORT'}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      jq '.deployment.status = "failed"' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
    fi
  
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: manual
      allow_failure: true
  
  dependencies:
    - build-feature-branch-shell

  artifacts:
    paths:
      - deployment-health-report.json
      - health-response.json
    expire_in: 1 week
    when: always

# Stop feature branch environment (cleanup)
stop-feature-branch:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 15m
  
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    action: stop
  
  variables:
    DEPLOY_ENV: "feature"
    DOCKER_TLS_CERTDIR: ""
  
  script: |
    # Generate dynamic port based on branch hash (same calculation as deploy)
    export DYNAMIC_PORT=$((5001 + (0x$(echo -n "$CI_COMMIT_REF_SLUG" | sha256sum | head -c 2) % 99)))
    echo "Stopping feature branch environment..."
    echo "Environment: review/$CI_COMMIT_REF_SLUG"
    echo "Port: $DYNAMIC_PORT"
    
    # Stop and clean up the feature branch deployment

    export COMPOSE_PROJECT_NAME="trakbridge-$CI_COMMIT_REF_SLUG"
    export FEATURE_BRANCH_PORT=$DYNAMIC_PORT
    export FEATURE_BRANCH_NAME="$CI_COMMIT_REF_SLUG"
      
    # Find and use deployment script to clean up
    if [ -f "./scripts/deploy.sh" ]; then
      chmod +x ./scripts/deploy.sh
      DEPLOY_SCRIPT="./scripts/deploy.sh"
    elif [ -f "$CI_PROJECT_DIR/scripts/deploy.sh" ]; then
      chmod +x "$CI_PROJECT_DIR/scripts/deploy.sh"
      DEPLOY_SCRIPT="$CI_PROJECT_DIR/scripts/deploy.sh"
    else
      DEPLOY_SCRIPT=""
    fi
    
    if [ -n "$DEPLOY_SCRIPT" ]; then
      echo "Using deployment script for cleanup: $DEPLOY_SCRIPT"
      $DEPLOY_SCRIPT \
        --environment feature \
        --action stop \
        --port $DYNAMIC_PORT \
        --branch "$CI_COMMIT_REF_SLUG" \
        --use-prebuilt \
        --verbose
    else
      # Fallback cleanup if script not available
      echo "Deployment script not found, using fallback cleanup..."
      docker-compose -p "trakbridge-$CI_COMMIT_REF_SLUG" down -v || echo "No containers to stop"
      
      # Clean up any containers on the dynamic port
      docker ps -q --filter "publish=$DYNAMIC_PORT" | xargs -r docker stop || echo "No containers on port $DYNAMIC_PORT"
    fi
    
    echo "Feature branch environment stopped and cleaned up"
  
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: manual
  
  dependencies: []

# =============================================================================
# PIPELINE COMPLETION
# =============================================================================

# Pipeline completion summary
pipeline-complete:
  stage: .post
  image: alpine:latest
  tags:
    - trakbridge-ops
  timeout: 2m
  script: |
    echo "TrakBridge GitLab CI/CD Pipeline completed successfully!"
    echo ""
    echo "Pipeline Summary:"
    echo "- Pipeline ID: $CI_PIPELINE_ID"
    echo "- Commit: $CI_COMMIT_SHA"
    echo "- Branch/Tag: ${CI_COMMIT_TAG:-$CI_COMMIT_REF_NAME}"
    echo "- Pipeline URL: $CI_PIPELINE_URL"
    echo ""
    
    if [ "$CI_COMMIT_BRANCH" == "$CI_DEFAULT_BRANCH" ] && [ -z "$CI_COMMIT_TAG" ]; then
      echo "  Development deployment completed"
      echo "   Built dev image: $IMAGE_NAME:dev"
      if [ -n "$CI_REGISTRY_IMAGE" ]; then
        echo "   GitLab Container Registry: $CI_REGISTRY_IMAGE:dev"
      fi
      echo "   Application URL: http://localhost:5000"
    elif [ -n "$CI_COMMIT_TAG" ]; then
      echo "  Production release completed"  
      echo "   Built tagged image: $IMAGE_NAME:$CI_COMMIT_TAG"
      if [ -n "$CI_REGISTRY_IMAGE" ]; then
        echo "   GitLab Container Registry: $CI_REGISTRY_IMAGE:$CI_COMMIT_TAG"
      fi
      echo "   Docker Hub: emfoursolutions/trakbridge:$CI_COMMIT_TAG"
    elif [ "$CI_COMMIT_BRANCH" != "$CI_DEFAULT_BRANCH" ] && [ -z "$CI_COMMIT_TAG" ]; then
      echo "  Feature branch validation completed"
      echo "   Branch: $CI_COMMIT_BRANCH"
      echo "   Built image: $IMAGE_NAME:$CI_COMMIT_REF_SLUG"
      if [ -n "$CI_REGISTRY_IMAGE" ]; then
        echo "   GitLab Container Registry: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG"
      fi
      echo "   Deploy manually using the 'deploy-feature-branch' job to test your changes"
      echo "   Feature deployments use dynamic ports (5001-5099 range)"
    else
      echo "  Code quality and security validation completed"
      echo "   Branch: $CI_COMMIT_BRANCH"
      echo "   All quality gates passed successfully"
    fi
    
    echo ""
    echo "  View detailed results: $CI_PIPELINE_URL"
    echo ""
    echo "   Slack notifications are configured through GitLab's native Slack app integration."
    echo "   Visit Project Settings > Integrations > GitLab for Slack app to configure notifications."
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH
  when: on_success

# =============================================================================
# INCLUDE TEMPLATES - GitLab Security Templates (Enhanced)
# =============================================================================

# Include GitLab's built-in security scanning templates
# Note: License-Scanning.gitlab-ci.yml was deprecated in GitLab 15.9 and removed in 16.3
# License compliance is now handled through Dependency-Scanning.gitlab-ci.yml
# Container-Scanning.gitlab-ci.yml removed - using custom Trivy implementation instead
include:
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/Dependency-Scanning.gitlab-ci.yml
  - template: Security/Secret-Detection.gitlab-ci.yml

# Override GitLab security templates to use TrakBridge runner tags
sast:
  stage: security
  tags:
    - trakbridge-ci

gemnasium-dependency_scanning:
  stage: security  
  tags:
    - trakbridge-ci

container_scanning:
  stage: security
  tags:
    - trakbridge-cd  # Needs Docker daemon access for container scanning
  timeout: 15m
  variables:
    CS_DOCKERFILE_PATH: "Dockerfile"
  before_script: |
    # Clean up any root-owned directories that may interfere with scanning
    echo "Cleaning up GitLab build directory permissions..."
    sudo find . -type d -name "data" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "logs" -exec chmod 755 {} \; 2>/dev/null || true
    sudo chown -R gitlab-runner:gitlab-runner data logs 2>/dev/null || true
  script: |
    echo "Running Trivy container scanning on $CS_IMAGE"
    if [ -n "$CS_IMAGE" ]; then
      # Create default report structure for GitLab compatibility
      echo '{"vulnerabilities": []}' > gl-container-scanning-report.json
      
      # Run Trivy scan with GitLab format
      trivy image --format json --output trivy-report.json "$CS_IMAGE" || echo "Trivy scan completed with warnings"
      
      # If Trivy found vulnerabilities, use its output
      if [ -f "trivy-report.json" ] && [ -s "trivy-report.json" ]; then
        mv trivy-report.json gl-container-scanning-report.json
      fi
      
      echo "Container scanning completed for $CS_IMAGE"
    else
      echo "No container image specified for scanning"
    fi
  artifacts:
    reports:
      container_scanning: gl-container-scanning-report.json
    paths:
      - gl-container-scanning-report.json
    when: always
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      needs: ["build-image-shell"]
      variables:
        CS_IMAGE: "$IMAGE_NAME:$CI_COMMIT_SHA"
    - if: $CI_COMMIT_TAG
      needs: ["build-tagged-image-shell"]  
      variables:
        CS_IMAGE: "$IMAGE_NAME:$CI_COMMIT_TAG"
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      needs: ["build-feature-branch-shell"]
      variables:
        CS_IMAGE: "$IMAGE_NAME:$CI_COMMIT_REF_SLUG"

.secret-analyzer:
  stage: security
  tags:
    - trakbridge-ci