# =============================================================================
# TrakBridge GitLab CI/CD Pipeline - Enhanced with Comprehensive Features
# =============================================================================
#
# Comprehensive CI/CD pipeline converted from GitHub Actions with GitLab enhancements:
# - Multi-environment deployments (development, staging, production)
# - Comprehensive testing suite (unit, integration, E2E, performance)
# - Enhanced security scanning with GitLab's built-in features
# - Container registry integration and multi-architecture builds
# - Native GitLab Slack app integration for notifications
# - Environment management with approval workflows
#
# =============================================================================

stages:
  - validate
  - test
  - build
  - security
  - cleanup
  - deploy
  - final-cleanup
  - notification

# Global variables - OPTIMIZED
variables:
  # Git configuration - CRITICAL for setuptools-scm
  GIT_DEPTH: 0
  GIT_STRATEGY: clone
  GIT_SUBMODULE_STRATEGY: none
  GIT_FETCH_EXTRA_FLAGS: "--tags"
    
  LINK_ARTIFACT: true
  DISCORD_WEBHOOK_URL: $WEBHOOK_URL  # Use your existing webhook variable

  # Python configuration
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  PYTHON_VERSION: "3.12"

  # Build optimization
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_CACHE_DIR: "false"

  # Application configuration
  APP_NAME: "trakbridge"

  # Container registry configuration
  REGISTRY: "docker.io"
  IMAGE_NAME: "$REGISTRY/$DOCKERHUB_USERNAME/$APP_NAME"

  # Test configuration
  PYTEST_ADDOPTS: "--strict-markers --strict-config --tb=short"
  COVERAGE_FILE: "$CI_PROJECT_DIR/.coverage"

  # Security scanning
  SAST_EXCLUDED_PATHS: "tests, docs, scripts"
  SECURE_LOG_LEVEL: "info"

# Reusable script for cross-platform package installation
.install_packages: &install_packages |
  install_packages() {
    # Detect package manager and install packages
    if command -v apt-get >/dev/null 2>&1; then
      echo "Using apt-get (Debian/Ubuntu)"
      apt-get update -qq && apt-get install -y -qq "$@"
    elif command -v dnf >/dev/null 2>&1; then
      echo "Using dnf (Rocky Linux/Fedora)"
      dnf install -y "$@"
    elif command -v yum >/dev/null 2>&1; then
      echo "Using yum (RHEL/CentOS)"
      yum install -y "$@"
    else
      echo "ERROR: No supported package manager found (apt-get, dnf, yum)"
      exit 1
    fi
  }

# Enhanced cache configuration
cache:
  - key: "pip-$CI_COMMIT_REF_SLUG-$PYTHON_VERSION"
    paths:
      - .pip-cache/
    policy: pull-push
  - key: "python-venv-$CI_COMMIT_REF_SLUG-$PYTHON_VERSION"
    paths:
      - .venv/
    policy: pull-push

# =============================================================================
# VALIDATE STAGE
# =============================================================================

validate-yaml:
  stage: validate
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 5m
  before_script:
    - pip install --no-cache-dir pyyaml
  script: |
    # Check if YAML files exist before validating
    if ls config/settings/*.yaml 1> /dev/null 2>&1; then
      echo "Validating YAML files..."
      for file in config/settings/*.yaml; do
        echo "Validating $file"
        python -c "import yaml; yaml.safe_load(open('$file'))"
      done
      echo "All YAML configuration files are valid"
    else
      echo "No YAML files found to validate"
    fi
  rules:
    - changes:
        - "config/**/*.yaml"
        - "config/**/*.yml"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

validate-requirements:
  stage: validate
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - *install_packages
    - install_packages git
    - pip install --upgrade pip
    - pip install --no-cache-dir pip-tools pip-audit
  script: |
    echo "Validating requirements.txt format..."

    if [ -f "requirements.txt" ]; then
      python -m pip install --dry-run -r requirements.txt
      echo "Requirements are valid and installable"
    else
      echo "No requirements.txt found"
    fi
    
    echo "Checking requirements for known vulnerabilities..."

    # Always create the audit report file
    if [ -f "requirements.txt" ]; then
      # Create a simple JSON report structure to avoid upload issues
      echo '{"vulnerabilities": []}' > audit-report.json
      
      # Run audit but don't fail the job on vulnerabilities
      if timeout 300 pip-audit --requirement requirements.txt --format json --output temp-audit.json; then
        mv temp-audit.json audit-report.json
      else
        echo "Audit completed with warnings or timeout"
      fi
      
      echo "Requirements security check completed"
    else
      echo '{"vulnerabilities": [], "message": "No requirements.txt found"}' > audit-report.json
    fi
  artifacts:
    reports:
      # Only include SAST report if it contains actual vulnerabilities
      sast: audit-report.json
    paths:
      - audit-report.json
    expire_in: 1 day
    when: always
  rules:
    - changes:
        - "requirements.txt"
        - "requirements.in"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

validate-pyproject:
  stage: validate
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - *install_packages
    - install_packages git
    - pip install --upgrade pip
    - pip install --no-cache-dir tomli validate-pyproject build setuptools-scm
  script: |
    echo "Validating pyproject.toml..."
    mkdir -p dist

    if [ -f "pyproject.toml" ]; then
      python -c "import tomli; tomli.load(open('pyproject.toml', 'rb'))"
      validate-pyproject pyproject.toml
      echo "Testing setuptools-scm version detection..."
      python -c "import setuptools_scm; print(f'Version: {setuptools_scm.get_version()}')"
      echo "Testing package build configuration..."
      python -m build --sdist --wheel --outdir dist/ .
      echo "pyproject.toml validation completed"
    else
      echo "No pyproject.toml found"
      echo "placeholder" > dist/.gitkeep
    fi
  artifacts:
    paths:
      - dist/
    expire_in: 1 hour
    when: always
  rules:
    - changes:
        - "pyproject.toml"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG

# =============================================================================
# TESTING STAGE
# =============================================================================

code-quality:
  stage: test
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - *install_packages
    - install_packages git jq
    - pip install --upgrade pip
    - pip install --no-cache-dir black flake8 isort
  script: |
    set +e  # Disable exit on error to ensure script always completes
    echo "Running code quality checks with GitLab reporting..."
    
    # Initialize Code Quality report
    echo '[]' > gl-code-quality-report.json
    
    # Run Black and generate report
    echo "Checking code formatting with Black..."
    if ! black --check --diff . > black-output.txt 2>&1 || true; then
      echo "Black formatting issues found"
      
      # Parse Black output and convert to GitLab Code Quality format
      while IFS= read -r line; do
        if [[ $line == *"would reformat"* ]]; then
          file=$(echo "$line" | grep -o '[^[:space:]]*\.py')
          if [[ -n "$file" ]]; then
            jq --null-input \
              --arg file "$file" \
              --arg description "Code formatting issue: file would be reformatted by Black" \
              --arg fingerprint "black-$file" \
              '{
                description: $description,
                check_name: "black",
                fingerprint: $fingerprint,
                severity: "minor",
                location: {
                  path: $file,
                  lines: {
                    begin: 1
                  }
                }
              }' >> black-issues.json
          fi
        fi
      done < black-output.txt
      
      if [[ -f black-issues.json ]]; then
        jq -s '.' black-issues.json > black-report.json
        jq '. + input' gl-code-quality-report.json black-report.json > temp.json && mv temp.json gl-code-quality-report.json
      fi
    fi
    
    # Run Flake8 and generate report
    echo "Checking code style with Flake8..."
    if ! flake8 . --max-line-length=100 --extend-ignore=E203,W503 \
      --exclude=.git,__pycache__,build,dist,.venv \
      --format='%(path)s:%(row)d:%(col)d: %(code)s %(text)s' > flake8-output.txt 2>&1 || true; then
      echo "Flake8 issues found"
      
      # Convert Flake8 output to GitLab Code Quality format
      while IFS= read -r line; do
        if [[ $line == *":"* ]]; then
          file=$(echo "$line" | cut -d: -f1)
          line_num=$(echo "$line" | cut -d: -f2)
          col_num=$(echo "$line" | cut -d: -f3)
          error_code=$(echo "$line" | cut -d: -f4 | awk '{print $1}')
          message=$(echo "$line" | cut -d: -f4 | cut -d' ' -f2-)
          
          jq --null-input \
            --arg file "$file" \
            --arg line "$line_num" \
            --arg description "Flake8 $error_code: $message" \
            --arg fingerprint "flake8-$file-$line_num-$error_code" \
            '{
              description: $description,
              check_name: "flake8",
              fingerprint: $fingerprint,
              severity: "minor",
              location: {
                path: $file,
                lines: {
                  begin: ($line | tonumber)
                }
              }
            }' >> flake8-issues.json
        fi
      done < flake8-output.txt
      
      if [[ -f flake8-issues.json ]]; then
        jq -s '.' flake8-issues.json > flake8-report.json
        jq '. + input' gl-code-quality-report.json flake8-report.json > temp.json && mv temp.json gl-code-quality-report.json
      fi
    fi
    
    # Run isort and generate report
    echo "Checking import sorting with isort..."
    if ! isort --check-only --diff . > isort-output.txt 2>&1 || true; then
      echo "Import sorting issues found"
      
      # Parse isort output and convert to GitLab Code Quality format
      while IFS= read -r line; do
        if [[ $line == *"Fixing"* ]] || [[ $line == *"Skipped"* ]]; then
          file=$(echo "$line" | grep -o '[^[:space:]]*\.py')
          if [[ -n "$file" ]]; then
            jq --null-input \
              --arg file "$file" \
              --arg description "Import sorting issue: imports not sorted according to isort configuration" \
              --arg fingerprint "isort-$file" \
              '{
                description: $description,
                check_name: "isort",
                fingerprint: $fingerprint,
                severity: "minor",
                location: {
                  path: $file,
                  lines: {
                    begin: 1
                  }
                }
              }' >> isort-issues.json
          fi
        fi
      done < isort-output.txt
      
      if [[ -f isort-issues.json ]]; then
        jq -s '.' isort-issues.json > isort-report.json
        jq '. + input' gl-code-quality-report.json isort-report.json > temp.json && mv temp.json gl-code-quality-report.json
      fi
    fi
    
    # Show summary
    issue_count=$(jq 'length' gl-code-quality-report.json)
    echo "Code quality check completed: $issue_count issues found"
    
    if [[ $issue_count -gt 0 ]]; then
      echo "Code quality issues detected - see GitLab Code Quality report"
    else
      echo "All code quality checks passed"
    fi
    
    # Always exit successfully regardless of quality issues
    exit 0
  
  artifacts:
    reports:
      codequality: gl-code-quality-report.json
    paths:
      - gl-code-quality-report.json
      - black-output.txt
      - flake8-output.txt
      - isort-output.txt
    expire_in: 1 week
    when: always
  
  allow_failure: false
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# =============================================================================
# UNIT TESTING STAGE - Comprehensive Test Suite
# =============================================================================

# PostgreSQL service for integration tests
.postgres_service: &postgres_service
  services:
    - name: postgres:15-alpine
      alias: postgres
      variables:
        POSTGRES_DB: test_db
        POSTGRES_USER: test_user
        POSTGRES_PASSWORD: test_password
        POSTGRES_HOST_AUTH_METHOD: trust

# Unit tests with coverage
unit-tests:
  stage: test
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 20m
  coverage: '/TOTAL.+?(\d+\%)$/'
  
  variables:
    # Use SQLite for fast unit tests
    DB_TYPE: "sqlite"
    FLASK_ENV: "testing"
    SECRET_KEY: "test-secret-key-for-gitlab-ci"
    TRAKBRIDGE_ENCRYPTION_KEY: "test-encryption-key-for-gitlab-ci-12345"
    COVERAGE_THRESHOLD: "20"
    # Ensure Python can find the project modules
    PYTHONPATH: "${CI_PROJECT_DIR}:${PYTHONPATH:-}"
  
  before_script:
    - *install_packages
    - install_packages git curl build-essential
    - pip install --upgrade pip
    - pip install -e ".[dev]"
  
  script: |
    echo "Running comprehensive unit test suite..."
    
    # Create unit test directory if it doesn't exist

    if [ ! -d "tests/unit" ]; then
      echo "No unit tests found - creating test directory structure"
      mkdir -p tests/unit
      echo "# Unit tests directory created" > tests/unit/__init__.py
      
      # Create basic unit test
      cat > tests/unit/test_basic_unit.py << 'EOF'
    """Basic unit tests for TrakBridge."""
    import pytest
    from app import create_app
    
    def test_app_creation():
        """Test that the Flask app can be created."""
        app = create_app('testing')
        assert app is not None
        assert app.config['TESTING'] is True
    
    def test_health_endpoint():
        """Test the health endpoint."""
        app = create_app('testing')
        with app.test_client() as client:
            response = client.get('/api/health')
            assert response.status_code == 200
            
    def test_basic_functionality():
        """Test basic application functionality."""
        app = create_app('testing')
        assert app.name == 'app'
    EOF
    fi
    
    # Run tests with comprehensive coverage reporting

    pytest tests/unit/ -v \
      --cov=. \
      --cov-report=xml \
      --cov-report=html \
      --cov-report=term-missing \
      --cov-fail-under=$COVERAGE_THRESHOLD \
      --cov-branch \
      --tb=short \
      --maxfail=10 \
      --durations=10 \
      --junitxml=unit-test-results.xml
    
    echo "Unit tests completed"
  
  artifacts:
    reports:
      junit: unit-test-results.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - htmlcov/
      - coverage.xml
      - unit-test-results.xml
      - tests/unit/
    expire_in: 14 days
  
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# Integration tests
integration-tests:
  stage: test
  image: python:${PYTHON_VERSION}-slim
  <<: *postgres_service
  tags:
    - trakbridge-ci
  timeout: 15m
  
  variables:
    # Use PostgreSQL for production-like integration tests
    DB_TYPE: "postgresql"
    DATABASE_URL: "postgresql://test_user:test_password@postgres:5432/test_db"
    FLASK_ENV: "testing"
    SECRET_KEY: "test-secret-key-for-gitlab-ci"
    TRAKBRIDGE_ENCRYPTION_KEY: "test-encryption-key-for-gitlab-ci-12345"
    # Ensure Python can find the project modules
    PYTHONPATH: "${CI_PROJECT_DIR}:${PYTHONPATH:-}"
  
  before_script:
    - *install_packages
    - install_packages git curl build-essential
    - pip install --upgrade pip
    - pip install -e ".[dev]"
  
  script: |
    echo "Running integration tests..."
    
    # Create integration test directory if it doesn't exist

    if [ ! -d "tests/integration" ]; then
      echo "No integration tests found - creating test directory structure"
      mkdir -p tests/integration
      echo "# Integration tests directory created" > tests/integration/__init__.py
      
      # Create basic integration test
      cat > tests/integration/test_basic_integration.py << 'EOF'
    """Basic integration tests for TrakBridge."""
    import pytest
    from database import db
    from models.stream import Stream
    from app import create_app
    
    @pytest.fixture
    def app():
        """Create test application."""
        app = create_app('testing')
        with app.app_context():
            db.create_all()
            yield app
            db.drop_all()
    
    @pytest.fixture
    def client(app):
        """Create test client."""
        return app.test_client()
    
    def test_health_endpoint_integration(client):
        """Test health endpoint with database integration."""
        response = client.get('/api/health')
        assert response.status_code == 200
        
    def test_database_connection(app):
        """Test database connection and basic operations."""
        with app.app_context():
            # Test basic database operations
            stream = Stream(name="Integration Test Stream", plugin_type="garmin")
            db.session.add(stream)
            db.session.commit()
            
            retrieved = Stream.query.filter_by(name="Integration Test Stream").first()
            assert retrieved is not None
            assert retrieved.name == "Integration Test Stream"
            assert retrieved.plugin_type == "garmin"
    EOF
    fi
  
    # Run integration tests
    pytest tests/integration/ -v --tb=short --maxfail=5 --durations=10 --junitxml=integration-test-results.xml
    
    echo "Integration tests completed"
  
  artifacts:
    reports:
      junit: integration-test-results.xml
    paths:
      - integration-test-results.xml
      - tests/integration/
    expire_in: 14 days
  
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# =============================================================================
# SECURITY STAGE
# =============================================================================

bandit-sast:
  stage: security
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 15m
  before_script:
    - *install_packages
    - install_packages git
    - pip install --upgrade pip
    - pip install --no-cache-dir bandit[toml]
  script: |
    echo "Running Bandit security scan..."

    # Always create a bandit report file
    echo '{"metrics": {"_totals": {"nosec": 0, "skipped_tests": 0}}, "results": []}' > bandit-report.json
    
    # Run bandit on existing directories only
    SCAN_DIRS=""
    for dir in app.py services plugins routes models config; do
      if [ -e "$dir" ]; then
        SCAN_DIRS="$SCAN_DIRS $dir"
      fi
    done
    
    if [ -n "$SCAN_DIRS" ]; then
      bandit -r $SCAN_DIRS -f json -o temp-bandit.json || true
      if [ -f "temp-bandit.json" ]; then
        mv temp-bandit.json bandit-report.json
      fi
      echo "Bandit security scan completed"
    else
      echo "No directories found to scan"
    fi
  artifacts:
    reports:
      sast: bandit-report.json
    paths:
      - bandit-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

safety-check:
  stage: security
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 10m
  before_script:
    - *install_packages
    - install_packages git jq
    - pip install --upgrade pip
    - pip install --no-cache-dir safety
  script: |
    echo "Running Safety vulnerability check with GitLab security reporting..."
    
    # Initialize GitLab security report
    cat > gl-dependency-scanning-report.json << 'EOF'
    {
      "version": "15.0.0",
      "vulnerabilities": [],
      "remediations": [],
      "scan": {
        "analyzer": {
          "id": "safety",
          "name": "Safety",
          "url": "https://pypi.org/project/safety/",
          "vendor": {
            "name": "PyUp.io"
          },
          "version": "latest"
        },
        "scanner": {
          "id": "safety",
          "name": "Safety",
          "url": "https://pypi.org/project/safety/",
          "vendor": {
            "name": "PyUp.io"
          },
          "version": "latest"
        },
        "type": "dependency_scanning",
        "start_time": "",
        "end_time": "",
        "status": "success"
      }
    }
    EOF
    
    # Set scan timestamps
    START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg start_time "$START_TIME" '.scan.start_time = $start_time' gl-dependency-scanning-report.json > temp.json && mv temp.json gl-dependency-scanning-report.json
    
    if [ -f "requirements.txt" ]; then
      echo "Scanning requirements.txt for vulnerabilities..."
      
      # Run safety check and capture output
      if [ -n "${SAFETY_API_KEY:-}" ]; then
        safety check --json --output safety-raw.json || SAFETY_EXIT_CODE=$?
      else
        safety check --json --output safety-raw.json --ignore-unpinned || SAFETY_EXIT_CODE=$?
      fi
      
      # Convert Safety JSON to GitLab security report format
      if [ -f "safety-raw.json" ] && [ -s "safety-raw.json" ]; then
        echo "Converting Safety report to GitLab format..."
        
        # Process each vulnerability from Safety report
        jq -r '.vulnerabilities[]? | @base64' safety-raw.json 2>/dev/null | while IFS= read -r vuln_b64; do
          if [ -n "$vuln_b64" ]; then
            vuln=$(echo "$vuln_b64" | base64 -d)
            
            # Extract vulnerability details
            package=$(echo "$vuln" | jq -r '.package_name // "unknown"')
            version=$(echo "$vuln" | jq -r '.analyzed_version // "unknown"')
            vuln_id=$(echo "$vuln" | jq -r '.vulnerability_id // "unknown"')
            advisory=$(echo "$vuln" | jq -r '.advisory // "No advisory available"')
            
            # Create GitLab vulnerability entry
            jq --null-input \
              --arg id "$vuln_id" \
              --arg package "$package" \
              --arg version "$version" \
              --arg advisory "$advisory" \
              --arg category "dependency_scanning" \
              --arg severity "Medium" \
              --arg confidence "High" \
              '{
                id: $id,
                category: $category,
                name: ("Vulnerability in " + $package),
                message: $advisory,
                description: $advisory,
                severity: $severity,
                confidence: $confidence,
                solution: "Upgrade to a fixed version",
                scanner: {
                  id: "safety",
                  name: "Safety"
                },
                location: {
                  file: "requirements.txt",
                  dependency: {
                    package: {
                      name: $package
                    },
                    version: $version
                  }
                },
                identifiers: [
                  {
                    type: "safety",
                    name: $id,
                    value: $id
                  }
                ]
              }' >> gl-vulnerabilities.json
          fi
        done
        
        # Merge vulnerabilities into main report
        if [ -f "gl-vulnerabilities.json" ]; then
          jq -s '.[0] as $report | .[1:] as $vulns | $report | .vulnerabilities = $vulns' gl-dependency-scanning-report.json gl-vulnerabilities.json > temp.json && mv temp.json gl-dependency-scanning-report.json
        fi
      fi
      
      # Keep original safety report as artifact
      cp safety-raw.json safety-report.json 2>/dev/null || echo '{"vulnerabilities": [], "scanned_packages": 0}' > safety-report.json
    else
      echo "No requirements.txt found for safety check"
      echo '{"vulnerabilities": [], "scanned_packages": 0}' > safety-report.json
    fi
    
    # Set end timestamp
    END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg end_time "$END_TIME" '.scan.end_time = $end_time' gl-dependency-scanning-report.json > temp.json && mv temp.json gl-dependency-scanning-report.json
    
    # Count vulnerabilities for summary
    vuln_count=$(jq '.vulnerabilities | length' gl-dependency-scanning-report.json)
    echo "Safety vulnerability check completed: $vuln_count vulnerabilities found"
    
  artifacts:
    reports:
      dependency_scanning: gl-dependency-scanning-report.json
    paths:
      - gl-dependency-scanning-report.json
      - safety-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

license-scanning:
  stage: security
  image: python:${PYTHON_VERSION}-slim
  tags:
    - trakbridge-ci
  timeout: 10m
  before_script:
    - *install_packages
    - install_packages git jq
    - pip install --upgrade pip
    - pip install --no-cache-dir pip-licenses
  script: |
    echo "Running license scanning with GitLab reporting..."
    
    # Initialize GitLab license scanning report
    cat > gl-license-scanning-report.json << 'EOF'
    {
      "version": "2.1",
      "licenses": [],
      "dependencies": [],
      "scan": {
        "analyzer": {
          "id": "pip-licenses",
          "name": "pip-licenses",
          "url": "https://pypi.org/project/pip-licenses/",
          "vendor": {
            "name": "pip-licenses"
          },
          "version": "latest"
        },
        "scanner": {
          "id": "pip-licenses",
          "name": "pip-licenses",
          "url": "https://pypi.org/project/pip-licenses/",
          "vendor": {
            "name": "pip-licenses"
          },
          "version": "latest"
        },
        "type": "license_scanning",
        "start_time": "",
        "end_time": "",
        "status": "success"
      }
    }
    EOF
    
    # Set scan timestamps
    START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg start_time "$START_TIME" '.scan.start_time = $start_time' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
    
    if [ -f "requirements.txt" ]; then
      echo "Installing dependencies and scanning licenses..."
      
      # Install dependencies from requirements.txt
      pip install -r requirements.txt || echo "Some dependencies failed to install"
      
      # Generate license report
      pip-licenses --format=json --output-file=pip-licenses-raw.json || echo "License scanning completed with warnings"
      
      # Convert pip-licenses output to GitLab format
      if [ -f "pip-licenses-raw.json" ] && [ -s "pip-licenses-raw.json" ]; then
        echo "Converting license report to GitLab format..."
        
        # Process each dependency
        jq -r '.[]? | @base64' pip-licenses-raw.json 2>/dev/null | while IFS= read -r dep_b64; do
          if [ -n "$dep_b64" ]; then
            dep=$(echo "$dep_b64" | base64 -d)
            
            # Extract dependency details
            name=$(echo "$dep" | jq -r '.Name // "unknown"')
            version=$(echo "$dep" | jq -r '.Version // "unknown"')
            license_name=$(echo "$dep" | jq -r '.License // "Unknown"')
            
            # Classify license risk level
            case "$license_name" in
              "MIT"|"Apache 2.0"|"Apache Software License"|"BSD"|"BSD License"|"3-Clause BSD"|"2-Clause BSD")
                classification="allowed"
                ;;
              "GPL"*|"AGPL"*|"LGPL"*)
                classification="denied"
                ;;
              "Unknown"|"UNKNOWN"|"")
                classification="unclassified"
                ;;
              *)
                classification="unclassified"
                ;;
            esac
            
            # Create license entry
            jq --null-input \
              --arg name "$license_name" \
              --arg classification "$classification" \
              '{
                key: $name,
                name: $name,
                spdx_identifier: $name,
                classification: $classification
              }' >> gl-licenses-temp.json
            
            # Create dependency entry
            jq --null-input \
              --arg name "$name" \
              --arg version "$version" \
              --arg license "$license_name" \
              --arg classification "$classification" \
              '{
                name: $name,
                version: $version,
                package_manager: "pip",
                path: "requirements.txt",
                licenses: [
                  {
                    key: $license,
                    name: $license,
                    spdx_identifier: $license
                  }
                ],
                classification: $classification
              }' >> gl-dependencies-temp.json
          fi
        done
        
        # Merge unique licenses and dependencies into main report
        if [ -f "gl-licenses-temp.json" ]; then
          jq -s 'unique_by(.key)' gl-licenses-temp.json > gl-licenses.json
          jq --slurpfile licenses gl-licenses.json '.licenses = $licenses[0]' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
        fi
        
        if [ -f "gl-dependencies-temp.json" ]; then
          jq -s 'unique_by(.name)' gl-dependencies-temp.json > gl-dependencies.json
          jq --slurpfile deps gl-dependencies.json '.dependencies = $deps[0]' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
        fi
      fi
      
      # Keep original pip-licenses report as artifact
      cp pip-licenses-raw.json pip-licenses-report.json 2>/dev/null || echo '[]' > pip-licenses-report.json
    else
      echo "No requirements.txt found for license scanning"
      echo '[]' > pip-licenses-report.json
    fi
    
    # Set end timestamp
    END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%S")
    jq --arg end_time "$END_TIME" '.scan.end_time = $end_time' gl-license-scanning-report.json > temp.json && mv temp.json gl-license-scanning-report.json
    
    # Count licenses and dependencies for summary
    license_count=$(jq '.licenses | length' gl-license-scanning-report.json)
    dep_count=$(jq '.dependencies | length' gl-license-scanning-report.json)
    denied_count=$(jq '[.dependencies[] | select(.classification == "denied")] | length' gl-license-scanning-report.json)
    
    echo "License scanning completed: $dep_count dependencies, $license_count unique licenses, $denied_count denied licenses"
    
    if [ "$denied_count" -gt 0 ]; then
      echo "WARNING: Found dependencies with denied licenses - review required"
    fi
    
  artifacts:
    reports:
      license_scanning: gl-license-scanning-report.json
    paths:
      - gl-license-scanning-report.json
      - pip-licenses-report.json
    expire_in: 1 week
    when: always
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH

# =============================================================================
# BUILD STAGE
# =============================================================================

build-image-shell:
  stage: build
  tags:
    - trakbridge-cd
  timeout: 45m
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
  before_script: |
    echo "Using host Docker daemon..."
    docker --version
    echo "Authenticating with GitLab Container Registry..."

    if [ -z "${CI_REGISTRY_USER}" ] || [ -z "${CI_REGISTRY_PASSWORD}" ]; then
      echo "Error: CI_REGISTRY_USER and CI_REGISTRY_PASSWORD must be set"
      exit 1
    fi
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"

    echo "Git information:"
    git --version
    git log --oneline -5 || echo "No git log available"
    git describe --tags --long --dirty || echo "No git describe available"
  script: |
    echo "Building container image with host Docker..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Tag: $CI_COMMIT_TAG"
    echo "Ref name: $CI_COMMIT_REF_NAME"

    # Set proper version for setuptools_scm
    if [ -n "$CI_COMMIT_TAG" ]; then
      export SETUPTOOLS_SCM_PRETEND_VERSION="$CI_COMMIT_TAG"
      echo "Using tag version: $CI_COMMIT_TAG"
    else
      export SETUPTOOLS_SCM_PRETEND_VERSION="0.1.0.dev0+g$CI_COMMIT_SHORT_SHA"
      echo "Using dev version: 0.1.0.dev0+g$CI_COMMIT_SHORT_SHA"
    fi

    # Build with better error handling
    if ! DOCKER_BUILDKIT=1 docker build \
      --target=production \
      --tag "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA" \
      --tag "$CI_REGISTRY_IMAGE:dev" \
      --label "org.opencontainers.image.source=$CI_PROJECT_URL" \
      --label "org.opencontainers.image.revision=$CI_COMMIT_SHA" \
      --label "org.opencontainers.image.created=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      --label "org.opencontainers.image.version=$CI_COMMIT_REF_NAME" \
      --label "org.opencontainers.image.title=$APP_NAME" \
      --build-arg SETUPTOOLS_SCM_PRETEND_VERSION="$SETUPTOOLS_SCM_PRETEND_VERSION" \
      --file Dockerfile \
      . ; then
      echo "Docker build failed"
      exit 1
    fi
    echo "Pushing dev image to GitLab Container Registry..."
    docker push "$CI_REGISTRY_IMAGE:dev"
    echo "Container build and push completed for dev image"
    echo "Pushed to: $CI_REGISTRY_IMAGE:dev"
  rules:
    - if: '$CI_COMMIT_TAG != null'
      when: never
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null

build-tagged-image-shell:
  stage: build
  tags:
    - trakbridge-cd
  timeout: 120m
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
  before_script: |
    echo "Using host Docker daemon..."
    docker --version
    echo "Authenticating with GitLab Container Registry for temporary image storage..."

    if [ -z "${CI_REGISTRY_USER}" ] || [ -z "${CI_REGISTRY_PASSWORD}" ]; then
      echo "Error: CI_REGISTRY_USER and CI_REGISTRY_PASSWORD must be set"
      exit 1
    fi
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"

    echo "Git information:"
    git --version
    git log --oneline -5 || echo "No git log available"
    git describe --tags --long --dirty || echo "No git describe available"
  script: |
    echo "🔨 Building multiplatform container image for staging validation (amd64, arm64)..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Tag: $CI_COMMIT_TAG"
    echo "Ref name: $CI_COMMIT_REF_NAME"
    echo ""
    echo "🔒 NOTE: This build creates images for validation only."
    echo "🔒 Images will be pushed to DockerHub only after successful staging validation."

    # Setup buildx for multiplatform builds
    echo "Setting up Docker Buildx for multiplatform builds..."
    docker buildx create --use --name multiarch --driver docker-container || true
    docker buildx inspect --bootstrap

    # For tagged builds, use the tag as version
    export SETUPTOOLS_SCM_PRETEND_VERSION="$CI_COMMIT_TAG"
    echo "Using tag version: $CI_COMMIT_TAG"

    # Build and push to GitLab Container Registry for staging validation
    if ! docker buildx build \
      --platform linux/amd64,linux/arm64 \
      --target=production \
      --tag "$CI_REGISTRY_IMAGE:$CI_COMMIT_TAG" \
      --tag "$CI_REGISTRY_IMAGE:release-candidate" \
      --label "org.opencontainers.image.source=$CI_PROJECT_URL" \
      --label "org.opencontainers.image.revision=$CI_COMMIT_SHA" \
      --label "org.opencontainers.image.created=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      --label "org.opencontainers.image.version=$CI_COMMIT_TAG" \
      --label "org.opencontainers.image.title=$APP_NAME" \
      --build-arg SETUPTOOLS_SCM_PRETEND_VERSION="$CI_COMMIT_TAG" \
      --file Dockerfile \
      --push \
      . ; then
      echo "Multiplatform Docker build failed"
      exit 1
    fi
    echo "✅ Multiplatform container build completed and stored in GitLab registry"
    echo "📋 Built images:"
    echo "   - $CI_REGISTRY_IMAGE:$CI_COMMIT_TAG"
    echo "   - $CI_REGISTRY_IMAGE:release-candidate"
    echo ""
    echo "⏳ Next: Staging validation will automatically test these images"
    echo "🔒 DockerHub publication requires manual approval after validation"
  rules:
    - if: $CI_COMMIT_TAG

# Feature branch build for development testing
build-feature-branch-shell:
  stage: build
  tags:
    - trakbridge-cd
  timeout: 45m
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
  before_script: |
    echo "Using host Docker daemon..."
    docker --version
    echo "Authenticating with GitLab Container Registry..."

    if [ -z "${CI_REGISTRY_USER}" ] || [ -z "${CI_REGISTRY_PASSWORD}" ]; then
      echo "Error: CI_REGISTRY_USER and CI_REGISTRY_PASSWORD must be set"
      exit 1
    fi
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"

    echo "Git information:"
    git --version
    git log --oneline -5 || echo "No git log available"
    git describe --tags --long --dirty || echo "No git describe available"
  script: |
    echo "Building feature branch container image with host Docker..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Ref name: $CI_COMMIT_REF_NAME"
    echo "Ref slug: $CI_COMMIT_REF_SLUG"

    # Set proper version for setuptools_scm for feature branches
    export SETUPTOOLS_SCM_PRETEND_VERSION="0.1.0.dev0+$CI_COMMIT_REF_SLUG.$CI_COMMIT_SHORT_SHA"
    echo "Using feature branch version: $SETUPTOOLS_SCM_PRETEND_VERSION"

    # Build with branch-specific tagging
    BRANCH_TAG="${CI_COMMIT_REF_SLUG}"
    
    if ! DOCKER_BUILDKIT=1 docker build \
      --target=production \
      --tag "$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA" \
      --tag "$CI_REGISTRY_IMAGE:$BRANCH_TAG" \
      --label "org.opencontainers.image.source=$CI_PROJECT_URL" \
      --label "org.opencontainers.image.revision=$CI_COMMIT_SHA" \
      --label "org.opencontainers.image.created=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
      --label "org.opencontainers.image.version=$CI_COMMIT_REF_NAME" \
      --label "org.opencontainers.image.title=$APP_NAME" \
      --label "org.opencontainers.image.branch=$CI_COMMIT_BRANCH" \
      --build-arg SETUPTOOLS_SCM_PRETEND_VERSION="$SETUPTOOLS_SCM_PRETEND_VERSION" \
      --file Dockerfile \
      . ; then
      echo "Docker build failed"
      exit 1
    fi
    echo "Pushing feature branch image to GitLab Container Registry..."
    docker push "$CI_REGISTRY_IMAGE:$BRANCH_TAG"
    echo "Feature branch container build and push completed for $BRANCH_TAG"
    echo "Pushed to: $CI_REGISTRY_IMAGE:$BRANCH_TAG"
  after_script: |
    # Clean up any root-owned directories created by Docker build
    echo "Cleaning up Docker build directory permissions..."
    sudo find . -type d -name "data" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "logs" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "build" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "dist" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "__pycache__" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -name "*.egg-info" -type d -exec chmod 755 {} \; 2>/dev/null || true
    sudo chown -R gitlab-runner:gitlab-runner . 2>/dev/null || true
    echo "Permission cleanup completed"
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: on_success

# =============================================================================
# CLEANUP STAGE - Build Directory Cleanup After Security
# =============================================================================

# Cleanup build artifacts after security scanning to prevent config conflicts
cleanup-build-artifacts:
  stage: cleanup
  image: alpine:latest
  tags:
    - trakbridge-ci
  timeout: 5m
  
  script: |
    echo "🧹 Complete workspace cleanup - removing all source code and build artifacts..."
    
    # Remove everything from the current directory
    # This forces deployment stages to pull fresh files from the repo as needed
    echo "Wiping entire workspace..."
    rm -rf ./* .[^.]* ..?* 2>/dev/null || true
    
    # Verify complete cleanup
    echo "=== VERIFICATION - Workspace after complete cleanup ==="
    ls -la
    echo ""
    echo "Directory should be completely empty except for hidden Git files"
    echo "Deployment stages will pull required files fresh from the repository"
    
    echo "✅ Complete workspace cleanup completed"
  
  rules:
    - if: $CI_COMMIT_TAG
      when: on_success
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: on_success
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: on_success

# =============================================================================
# DEPLOYMENT STAGE - Environment-specific Deployments
# =============================================================================

# Development deployment
deploy-development:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 30m
  
  environment:
    name: development
    url: http://localhost:5000
    deployment_tier: development
  
  variables:
    DEPLOY_ENV: "development"
    APP_VERSION: "${CI_COMMIT_REF_NAME}-${CI_COMMIT_SHORT_SHA}"
    DOCKER_TLS_CERTDIR: ""
  
  before_script: |
    # Authenticate with GitLab Container Registry
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"

    # Create directory structure for deployment
    mkdir -p scripts/
    
    # Download deployment files from GitLab repository
    REPO_API_URL="${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/repository"

    echo "Downloading docker-compose-dev.yml..."
    curl -H "PRIVATE-TOKEN: ${CI_JOB_TOKEN}" \
         "${REPO_API_URL}/files/docker-compose.dev.yml/raw?ref=${CI_COMMIT_SHA}" \
         -o docker-compose.dev.yml
    
    echo "Downloading deploy.sh..."
    curl -H "PRIVATE-TOKEN: ${CI_JOB_TOKEN}" \
         "${REPO_API_URL}/files/scripts%2Fdeploy.sh/raw?ref=${CI_COMMIT_SHA}" \
         -o scripts/deploy.sh
    chmod +x scripts/deploy.sh


  script: |
    echo "Deploying to development environment..."
    
    # Use the built development image (already available locally from build-image-shell)
    echo "Using local development image: $CI_REGISTRY_IMAGE:dev"
    if docker image inspect $CI_REGISTRY_IMAGE:dev > /dev/null 2>&1; then
      # Tag it with the name the deploy script expects for --environment development
      docker tag $CI_REGISTRY_IMAGE:dev $CI_REGISTRY_IMAGE:development
      echo "Successfully tagged local development image as $CI_REGISTRY_IMAGE:development"
    else
      echo "ERROR: Local development image not found: $CI_REGISTRY_IMAGE:dev"
      echo "This usually means the build-image-shell job failed or didn't run"
      echo "Available images:"
      docker images | grep "$CI_REGISTRY_IMAGE" || echo "No images found with registry prefix"
      exit 1
    fi
    
    # Export GitLab CI variables for Docker Compose
    echo "Exporting GitLab CI variables for Docker Compose..."
    export LDAP_SERVER="${LDAP_SERVER:-ldap://your-ad-server.company.com}"
    export LDAP_ENABLED="${LDAP_ENABLED:-false}"
    export LDAP_PORT="${LDAP_PORT:-389}"
    export LDAP_USE_SSL="${LDAP_USE_SSL:-false}"
    export LDAP_USE_TLS="${LDAP_USE_TLS:-false}"
    export LDAP_VALIDATE_CERT="${LDAP_VALIDATE_CERT:-false}"
    export LDAP_BIND_DN="${LDAP_BIND_DN:-CN=trakbridge,OU=Service Accounts,DC=company,DC=com}"
    export LDAP_BIND_PASSWORD="${LDAP_BIND_PASSWORD:-default-ldap-password}"
    export LDAP_USER_SEARCH_BASE="${LDAP_USER_SEARCH_BASE:-OU=Users,DC=company,DC=com}"
    export LDAP_USER_SEARCH_FILTER="${LDAP_USER_SEARCH_FILTER}"
    export LDAP_GROUP_SEARCH_BASE="${LDAP_GROUP_SEARCH_BASE:-OU=Groups,DC=company,DC=com}"
    export LDAP_GROUP_SEARCH_FILTER="${LDAP_GROUP_SEARCH_FILTER}"
    export LDAP_ADMIN_GROUP="${LDAP_ADMIN_GROUP:-CN=TrakBridge-Admins,OU=Groups,DC=company,DC=com}"
    export LDAP_OPERATOR_GROUP="${LDAP_OPERATOR_GROUP:-CN=TrakBridge-Operators,OU=Groups,DC=company,DC=com}"
    export LDAP_USER_GROUP="${LDAP_USER_GROUP:-CN=TrakBridge-Users,OU=Groups,DC=company,DC=com}"
    export LDAP_DEFAULT_ROLE="${LDAP_DEFAULT_ROLE:-user}"
    export LDAP_CONNECTION_TIMEOUT="${LDAP_CONNECTION_TIMEOUT:-10}"
    export LDAP_RESPONSE_TIMEOUT="${LDAP_RESPONSE_TIMEOUT:-30}"
    
    # OIDC/SSO Settings
    export OIDC_ENABLED="${OIDC_ENABLED:-false}"
    export OIDC_ISSUER="${OIDC_ISSUER:-https://your-identity-provider.com}"
    export OIDC_CLIENT_ID="${OIDC_CLIENT_ID:-trakbridge-client}"
    export OIDC_CLIENT_SECRET="${OIDC_CLIENT_SECRET:-default-oidc-secret}"
    export OIDC_REDIRECT_URI="${OIDC_REDIRECT_URI:-http://localhost:5000/auth/oidc/callback}"
    export OIDC_VERIFY_SIGNATURE="${OIDC_VERIFY_SIGNATURE:-false}"
    export OIDC_VERIFY_AUDIENCE="${OIDC_VERIFY_AUDIENCE:-false}"
    export OIDC_VERIFY_ISSUER="${OIDC_VERIFY_ISSUER:-false}"
    export OIDC_ADMIN_GROUP="${OIDC_ADMIN_GROUP:-trakbridge-admins}"
    export OIDC_OPERATOR_GROUP="${OIDC_OPERATOR_GROUP:-trakbridge-operators}"
    export OIDC_USER_GROUP="${OIDC_USER_GROUP:-trakbridge-users}"
    export OIDC_DEFAULT_ROLE="${OIDC_DEFAULT_ROLE:-user}"
    
    echo "LDAP_SERVER will be set to: $LDAP_SERVER"
    echo "LDAP_BIND_PASSWORD length: ${#LDAP_BIND_PASSWORD}"
    echo "LDAP_BIND_PASSWORD first 10 chars: ${LDAP_BIND_PASSWORD:0:10}..."
    
    # Export dynamic user variables for Docker runtime user creation
    export USER_ID=${USER_ID:-$(id -u)}
    export GROUP_ID=${GROUP_ID:-$(id -g)}
    
    # Set the application port to match docker-compose-dev.yml
    export APP_PORT=5000
    
    # Don't override CI_REGISTRY_IMAGE - let it use the GitLab registry name
    # The deploy script will set IMAGE_TAG="development" for --environment development
    
    # Clean up any existing containers on port 5000 to prevent port conflicts
    echo "Cleaning up any existing containers using port 5000..."
    docker ps -q --filter "publish=5000" | xargs -r docker stop || echo "No containers using port 5000"
    docker ps -aq --filter "publish=5000" | xargs -r docker rm || echo "No stopped containers to remove"

    # Also check for containers with the default name
    docker ps -q --filter "name=trakbridge" | xargs -r docker stop || echo "No trakbridge containers running"
    docker ps -aq --filter "name=trakbridge" | xargs -r docker rm || echo "No trakbridge containers to remove"
    
    # Set up development environment using deployment script
    chmod +x scripts/deploy.sh

    scripts/deploy.sh \
      --environment development \
      --action deploy \
      --profiles postgres \
      --timeout 300 \
      --use-prebuilt \
      --skip-health-check \
      --verbose
    
    # Debug: Check environment variables inside the container
    echo "=== CONTAINER ENVIRONMENT DEBUG ==="
    docker exec trakbridge env | grep LDAP || echo "No LDAP environment variables found"
    echo "Container LDAP_BIND_PASSWORD length:"
    docker exec trakbridge sh -c 'echo ${#LDAP_BIND_PASSWORD}' || echo "LDAP_BIND_PASSWORD not set in container"
    echo "=== END CONTAINER DEBUG ==="
    
    echo "Development deployment completed"
    echo "Application URL: http://localhost:5000"
    echo "Default login: admin / TrakBridge-Setup-2025!"
  
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "web" && $DEPLOY_ENVIRONMENT == "development"
  
  dependencies:
    - build-image-shell
    - cleanup-build-artifacts
  
  after_script:
    - |
      # Generate deployment health report
      echo "Generating deployment health report..."
      
      # Create deployment report
      cat > deployment-health-report.json << EOF
      {
        "deployment": {
          "environment": "development",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "status": "success",
          "url": "http://localhost:5000",
          "version": "${CI_COMMIT_SHA}",
          "branch": "${CI_COMMIT_BRANCH}"
        },
        "health_checks": [],
        "metrics": {
          "deployment_duration": "${SECONDS:-0}",
          "services_count": 0,
          "containers_running": 0
        }
      }
      EOF
      
      # Test application health
      if curl -f -s http://localhost:5000/api/health > health-response.json 2>/dev/null; then
        echo "✅ Health check passed"
        jq '.health_checks += [{"name": "api_health", "status": "pass", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      else
        echo "❌ Health check failed"
        jq '.health_checks += [{"name": "api_health", "status": "fail", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
        jq '.deployment.status = "failed"' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
        
        # Add debug logs for failed health check
        echo "=== DEBUG: Container logs after health check failure ==="
        docker logs trakbridge --tail=30 || echo "Could not get app container logs"
        echo "=== END DEBUG LOGS ==="
      fi
      
      # Count running containers
      if command -v docker > /dev/null 2>&1; then
        running_containers=$(docker ps --filter "label=com.docker.compose.project=trakbridge" --format "table {{.Names}}" | tail -n +2 | wc -l)
        jq --argjson count "$running_containers" '.metrics.containers_running = $count' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      fi
      
      echo "Deployment health report generated"

  artifacts:
    paths:
      - deployment-health-report.json
      - health-response.json
    expire_in: 1 week
    when: always

# Production-Mirrored Staging Deployment - Pre-Release Validation
staging-production-mirror:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 90m  # Extended for comprehensive multi-database testing
  
  # Use deployment-only approach (no source clone)
  variables:
    GIT_STRATEGY: none
    DEPLOY_ENV: "staging"
    APP_VERSION: "${CI_COMMIT_TAG}"
    DOCKER_TLS_CERTDIR: ""
    COMPOSE_FILE: "docker-compose.staging.yml"
  
  environment:
    name: staging-production-mirror
    url: http://localhost:5000
    deployment_tier: staging
  
  before_script: |
    echo "🚀 Starting Production-Mirrored Staging Validation for Release: ${CI_COMMIT_TAG}"
    echo "📦 Using deployment-only approach (no source clone) - mirroring production deployment"
    echo "🔍 This validation gates the release before DockerHub publication"
    echo ""
    
    # Verify required tools are available on the runner
    echo "Checking for required tools..."
    command -v curl >/dev/null 2>&1 || { echo "ERROR: curl not found"; exit 1; }
    command -v jq >/dev/null 2>&1 || { echo "ERROR: jq not found"; exit 1; }
    command -v python3 >/dev/null 2>&1 || { echo "ERROR: python3 not found"; exit 1; }
    echo "✅ All required tools are available"
    
    # Authenticate with GitLab Container Registry to pull built images
    if [ -z "${CI_REGISTRY_USER}" ] || [ -z "${CI_REGISTRY_PASSWORD}" ]; then
      echo "Error: CI_REGISTRY_USER and CI_REGISTRY_PASSWORD must be set"
      exit 1
    fi
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"
    
    # Clean up any existing test environment
    echo "Cleaning up any existing test containers..."
    docker compose down -v --remove-orphans 2>/dev/null || true
    docker system prune -f --volumes 2>/dev/null || true
    
    # Download required deployment files using GitLab API
    echo "📥 Downloading deployment files for tag: ${CI_COMMIT_TAG}..."
    
    # Create directory structure for deployment
    mkdir -p scripts/ logs/ data/ secrets/ backups/ external_plugins/
    
    # Download deployment files from GitLab repository
    REPO_API_URL="${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/repository"
    
    echo "Downloading setup.sh..."
    curl -H "PRIVATE-TOKEN: ${CI_JOB_TOKEN}" \
         "${REPO_API_URL}/files/scripts%2Fsetup.sh/raw?ref=${CI_COMMIT_TAG}" \
         -o scripts/setup.sh
    chmod +x scripts/setup.sh
    
    echo "Downloading docker-compose.staging.yml..."
    curl -H "PRIVATE-TOKEN: ${CI_JOB_TOKEN}" \
         "${REPO_API_URL}/files/docker-compose.staging.yml/raw?ref=${CI_COMMIT_TAG}" \
         -o docker-compose.staging.yml
    
    echo "Downloading test-database.sh..."
    curl -H "PRIVATE-TOKEN: ${CI_JOB_TOKEN}" \
         "${REPO_API_URL}/files/scripts%2Ftest-database.sh/raw?ref=${CI_COMMIT_TAG}" \
         -o scripts/test-database.sh
    chmod +x scripts/test-database.sh
    
    echo "✅ Deployment files downloaded successfully"
    ls -la scripts/ *.yml
  
  script: |
    echo "🔧 Setting up production-like secrets and configuration..."
    
    # Run setup.sh to create production-like directory structure and secrets
    chmod +x scripts/setup.sh
    scripts/setup.sh --force
    
    # Fix file permissions for Docker container (setup.sh creates files as runner user 980:980, container runs as 1000:1000)
    echo "🔧 Fixing file permissions for Docker container..."
    if command -v sudo >/dev/null 2>&1; then
      sudo chown -R 1000:1000 logs/ data/ secrets/ config/ backups/ external_plugins/ external_config/ 2>/dev/null || true
      echo "✅ Fixed ownership using sudo"
    else
      # Fallback: make directories world-accessible
      chmod -R 755 logs/ data/ config/ backups/ external_plugins/ external_config/ 2>/dev/null || true
      chmod -R 644 secrets/* 2>/dev/null || true
      chmod 755 secrets/ 2>/dev/null || true
      echo "✅ Fixed permissions using chmod (no sudo available)"
    fi
    
    # Pre-create database-specific backup directories to prevent Docker from creating them as root
    echo "🗂️ Pre-creating database-specific backup directories..."
    mkdir -p backups/postgres-staging backups/mysql-staging backups/staging 2>/dev/null || true
    if command -v sudo >/dev/null 2>&1; then
      sudo chown -R 1000:1000 backups/postgres-staging backups/mysql-staging backups/staging 2>/dev/null || true
      echo "✅ Fixed backup subdirectory ownership using sudo"
    else
      chmod -R 755 backups/postgres-staging backups/mysql-staging backups/staging 2>/dev/null || true
      echo "✅ Fixed backup subdirectory permissions using chmod"
    fi
    
    # Inject LDAP password from GitLab CI/CD variable into secrets file
    if [ -n "${LDAP_BIND_PASSWORD}" ]; then
      echo "Injecting LDAP password from GitLab CI variable..."
      echo "${LDAP_BIND_PASSWORD}" > secrets/ldap_bind_password
      chmod 600 secrets/ldap_bind_password
      # Fix ownership after file injection (file gets created as runner user)
      if command -v sudo >/dev/null 2>&1; then
        sudo chown 1000:1000 secrets/ldap_bind_password 2>/dev/null || true
      fi
      echo "LDAP password injected successfully (length: ${#LDAP_BIND_PASSWORD} chars)"
    else
      echo "WARNING: LDAP_BIND_PASSWORD not set in GitLab CI variables"
      echo "LDAP authentication tests may fail"
    fi
    
    # Set production-like environment configuration
    export LDAP_ENABLED="${LDAP_ENABLED:-true}"
    export LDAP_SERVER="${LDAP_SERVER:-ldap://your-ad-server.company.com}"
    export LDAP_PORT="${LDAP_PORT:-389}"
    export LDAP_USE_SSL="${LDAP_USE_SSL:-false}"
    export LDAP_USE_TLS="${LDAP_USE_TLS:-true}"
    export LDAP_VALIDATE_CERT="${LDAP_VALIDATE_CERT:-true}"
    export LDAP_BIND_DN="${LDAP_BIND_DN:-CN=trakbridge,OU=Service Accounts,DC=company,DC=com}"
    export LDAP_USER_SEARCH_BASE="${LDAP_USER_SEARCH_BASE:-OU=Users,DC=company,DC=com}"
    export LDAP_USER_SEARCH_FILTER="${LDAP_USER_SEARCH_FILTER:-(sAMAccountName={username})}"
    export LDAP_GROUP_SEARCH_BASE="${LDAP_GROUP_SEARCH_BASE:-OU=Groups,DC=company,DC=com}"
    export LDAP_GROUP_SEARCH_FILTER="${LDAP_GROUP_SEARCH_FILTER:-member={user_dn}}"
    export LDAP_ADMIN_GROUP="${LDAP_ADMIN_GROUP:-CN=TrakBridge-Admins,OU=Groups,DC=company,DC=com}"
    export LDAP_OPERATOR_GROUP="${LDAP_OPERATOR_GROUP:-CN=TrakBridge-Operators,OU=Groups,DC=company,DC=com}"
    export LDAP_USER_GROUP="${LDAP_USER_GROUP:-CN=TrakBridge-Users,OU=Groups,DC=company,DC=com}"
    export LDAP_DEFAULT_ROLE="${LDAP_DEFAULT_ROLE:-user}"
    export LDAP_CONNECTION_TIMEOUT="${LDAP_CONNECTION_TIMEOUT:-10}"
    export LDAP_RESPONSE_TIMEOUT="${LDAP_RESPONSE_TIMEOUT:-30}"
    
    # OIDC/SSO Settings
    export OIDC_ENABLED="${OIDC_ENABLED:-false}"
    export OIDC_ISSUER="${OIDC_ISSUER:-https://your-identity-provider.com}"
    export OIDC_CLIENT_ID="${OIDC_CLIENT_ID:-trakbridge-client}"
    export OIDC_REDIRECT_URI="${OIDC_REDIRECT_URI:-https://localhost/auth/oidc/callback}"
    export OIDC_VERIFY_SIGNATURE="${OIDC_VERIFY_SIGNATURE:-true}"
    export OIDC_VERIFY_AUDIENCE="${OIDC_VERIFY_AUDIENCE:-true}"
    export OIDC_VERIFY_ISSUER="${OIDC_VERIFY_ISSUER:-true}"
    export OIDC_ADMIN_GROUP="${OIDC_ADMIN_GROUP:-trakbridge-admins}"
    export OIDC_OPERATOR_GROUP="${OIDC_OPERATOR_GROUP:-trakbridge-operators}"
    export OIDC_USER_GROUP="${OIDC_USER_GROUP:-trakbridge-users}"
    export OIDC_DEFAULT_ROLE="${OIDC_DEFAULT_ROLE:-user}"
    
    # Set Docker user/group for file permissions
    export USER_ID=${USER_ID:-$(id -u)}
    export GROUP_ID=${GROUP_ID:-$(id -g)}
    
    # Pull the built release candidate image from GitLab registry
    export IMAGE_NAME="$CI_REGISTRY_IMAGE:$CI_COMMIT_TAG"
    echo "Using release candidate image from GitLab registry: $IMAGE_NAME"
    docker pull "$IMAGE_NAME"
    
    # Also tag as local name for docker-compose compatibility
    docker tag "$IMAGE_NAME" "emfoursolutions/trakbridge:$CI_COMMIT_TAG"
    
    # Initialize comprehensive test results
    cat > staging-test-results.json << 'EOF'
    {
      "test_run": {
        "timestamp": "",
        "release_tag": "",
        "total_tests": 3,
        "passed": 0,
        "failed": 0,
        "status": "running"
      },
      "database_tests": []
    }
    EOF
    
    jq --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" --arg tag "${CI_COMMIT_TAG}" \
      '.test_run.timestamp = $timestamp | .test_run.release_tag = $tag' \
      staging-test-results.json > temp.json && mv temp.json staging-test-results.json
    
    # Sequential Database Testing
    echo ""
    echo "🗄️  Starting Sequential Database Testing..."
    echo "Testing Order: PostgreSQL → MySQL → SQLite"
    echo ""
    
    TEST_FAILED=false
    
    # Test PostgreSQL
    echo "📊 Testing PostgreSQL Database..."
    if ./scripts/test-database.sh "postgresql" "postgres" "${CI_COMMIT_TAG}"; then
      echo "✅ PostgreSQL test PASSED"
      jq '.database_tests += [{"database": "postgresql", "status": "passed", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      jq '.test_run.passed += 1' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
    else
      echo "❌ PostgreSQL test FAILED"
      jq '.database_tests += [{"database": "postgresql", "status": "failed", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      jq '.test_run.failed += 1' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      TEST_FAILED=true
    fi
    
    # Test MySQL  
    echo "📊 Testing MySQL Database..."
    if ./scripts/test-database.sh "mysql" "mysql" "${CI_COMMIT_TAG}"; then
      echo "✅ MySQL test PASSED"
      jq '.database_tests += [{"database": "mysql", "status": "passed", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      jq '.test_run.passed += 1' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
    else
      echo "❌ MySQL test FAILED"
      jq '.database_tests += [{"database": "mysql", "status": "failed", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      jq '.test_run.failed += 1' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      TEST_FAILED=true
    fi
    
    # Test SQLite
    echo "📊 Testing SQLite Database..."
    # Clear DB_NAME to ensure SQLite uses config defaults (data/app.db) instead of 
    # PostgreSQL/MySQL values (trakbridge) that persist from previous tests
    unset DB_NAME
    if ./scripts/test-database.sh "sqlite" "" "${CI_COMMIT_TAG}"; then
      echo "✅ SQLite test PASSED"
      jq '.database_tests += [{"database": "sqlite", "status": "passed", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      jq '.test_run.passed += 1' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
    else
      echo "❌ SQLite test FAILED"
      jq '.database_tests += [{"database": "sqlite", "status": "failed", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}]' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      jq '.test_run.failed += 1' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      TEST_FAILED=true
    fi
    
    # Final test results
    if [ "$TEST_FAILED" = true ]; then
      jq '.test_run.status = "failed"' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      echo ""
      echo "❌ STAGING VALIDATION FAILED"
      echo "One or more database tests failed. Review test results before proceeding to production."
      exit 1
    else
      jq '.test_run.status = "passed"' staging-test-results.json > temp.json && mv temp.json staging-test-results.json
      echo ""
      echo "✅ STAGING VALIDATION PASSED"
      echo "All database types validated successfully. Release ${CI_COMMIT_TAG} is ready for production!"
    fi
    
    # Clean up build files and test artifacts after all tests complete
    echo "🧹 Cleaning up build files and test artifacts..."
    docker-compose -f docker-compose.staging.yml down --volumes --remove-orphans 2>/dev/null || true
    docker system prune -f --volumes 2>/dev/null || true
    rm -rf data logs backups secrets external_plugins config 2>/dev/null || true
    rm -f docker-compose.override.yml 2>/dev/null || true
    echo "✅ Cleanup completed"
  
  rules:
    # Automatic trigger on tagged releases after successful build
    - if: $CI_COMMIT_TAG
      when: on_success
      allow_failure: false
  
  needs:
    - job: build-tagged-image-shell
      artifacts: false
  
  after_script:
    - |
      echo "🧹 Cleaning up staging test environment..."
      
      # Ensure all test containers are stopped and removed
      docker compose down -v --remove-orphans 2>/dev/null || true
      
      # Clean up any test data volumes
      docker volume prune -f 2>/dev/null || true
      
      # Generate final deployment health report
      cat > staging-deployment-health.json << EOF
      {
        "deployment": {
          "environment": "staging-production-mirror",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "status": "completed",
          "release_tag": "${CI_COMMIT_TAG}",
          "duration_seconds": "${SECONDS:-0}"
        },
        "validation_summary": {
          "databases_tested": ["postgresql", "mysql", "sqlite"],
          "total_duration": "${SECONDS:-0}",
          "secrets_validated": true,
          "ldap_connectivity": true,
          "migrations_tested": true
        }
      }
      EOF
      
      echo "Staging validation completed for release: ${CI_COMMIT_TAG}"
      echo "Duration: ${SECONDS:-0} seconds"

  artifacts:
    paths:
      - staging-test-results.json
      - staging-deployment-health.json
      - logs/
      - test-reports/
    expire_in: 1 month  # Keep staging validation results longer
    when: always
    reports:
      junit: test-reports/junit-*.xml

# DockerHub Release Deployment - Final Release Gate
deploy-to-dockerhub:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 30m
  
  environment:
    name: production-release
    deployment_tier: production
  
  variables:
    DOCKER_TLS_CERTDIR: ""
  
  before_script: |
    echo "🚀 Publishing validated release to DockerHub: ${CI_COMMIT_TAG}"
    echo "This job publishes staging-validated images to public DockerHub registry"
    echo ""
    echo "✅ Pre-requisites verified:"
    echo "   - Build completed successfully"
    echo "   - Staging validation passed for all database types"
    echo "   - Manual approval granted"
    echo ""
    
    # Authenticate with both registries
    echo "Authenticating with GitLab Container Registry (source)..."
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"
    
    echo "Authenticating with DockerHub (destination)..."
    if [ -z "${DOCKERHUB_USERNAME}" ] || [ -z "${DOCKERHUB_TOKEN}" ]; then
      echo "Error: DOCKERHUB_USERNAME and DOCKERHUB_TOKEN must be set for production release"
      exit 1
    fi
    echo "${DOCKERHUB_TOKEN}" | docker login --username "${DOCKERHUB_USERNAME}" --password-stdin docker.io
  
  script: |
    echo "📦 Pulling validated images from GitLab Container Registry..."
    
    # Pull the validated release candidate images
    SOURCE_IMAGE="$CI_REGISTRY_IMAGE:$CI_COMMIT_TAG"
    echo "Source image: $SOURCE_IMAGE"
    docker pull "$SOURCE_IMAGE"
    
    # Tag for DockerHub release
    DOCKERHUB_IMAGE="$IMAGE_NAME:$CI_COMMIT_TAG"
    DOCKERHUB_LATEST="$IMAGE_NAME:latest"
    
    echo "🏷️  Tagging images for DockerHub release..."
    docker tag "$SOURCE_IMAGE" "$DOCKERHUB_IMAGE"
    docker tag "$SOURCE_IMAGE" "$DOCKERHUB_LATEST"
    
    echo "📋 Release images:"
    echo "   - $DOCKERHUB_IMAGE"
    echo "   - $DOCKERHUB_LATEST"
    
    echo "🚀 Pushing validated release to DockerHub..."
    docker push "$DOCKERHUB_IMAGE"
    docker push "$DOCKERHUB_LATEST"
    
    echo ""
    echo "✅ PRODUCTION RELEASE COMPLETED"
    echo "🎉 Release $CI_COMMIT_TAG has been published to DockerHub!"
    echo ""
    echo "📋 Published images:"
    echo "   - $DOCKERHUB_IMAGE (tagged release)"
    echo "   - $DOCKERHUB_LATEST (latest release)"
    echo ""
    echo "🔗 DockerHub: https://hub.docker.com/r/emfoursolutions/trakbridge"
    echo "📦 Pull command: docker pull $DOCKERHUB_IMAGE"
    
    # Generate release report
    cat > production-release-report.json << EOF
    {
      "release": {
        "tag": "$CI_COMMIT_TAG",
        "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
        "status": "published",
        "dockerhub_images": [
          "$DOCKERHUB_IMAGE",
          "$DOCKERHUB_LATEST"
        ],
        "validation_passed": true,
        "manual_approval": true
      },
      "pipeline": {
        "build_job": "build-tagged-image-shell",
        "validation_job": "staging-production-mirror",
        "release_job": "deploy-to-dockerhub",
        "pipeline_id": "$CI_PIPELINE_ID",
        "pipeline_url": "$CI_PIPELINE_URL"
      }
    }
    EOF
    
    echo "📋 Production release report generated: production-release-report.json"
  
  rules:
    # Manual trigger on tagged releases, only after successful staging validation
    - if: $CI_COMMIT_TAG
      when: manual
      allow_failure: false
  
  needs:
    - job: staging-production-mirror
      artifacts: false
  
  after_script:
    - |
      echo "🧹 Cleaning up local Docker images..."
      
      # Clean up local copies to save space
      docker rmi "$CI_REGISTRY_IMAGE:$CI_COMMIT_TAG" 2>/dev/null || true
      docker rmi "$IMAGE_NAME:$CI_COMMIT_TAG" 2>/dev/null || true
      docker rmi "$IMAGE_NAME:latest" 2>/dev/null || true
      
      echo "✅ Production release process completed"
      echo "🎯 Release $CI_COMMIT_TAG is now available for production deployment"

  artifacts:
    paths:
      - production-release-report.json
    expire_in: 1 year  # Keep production release records longer
    when: always


# Feature branch dynamic environment deployment
deploy-feature-branch:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 30m
  
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    url: http://localhost:5001
    deployment_tier: development
    auto_stop_in: 1 week
    on_stop: stop-feature-branch
  
  variables:
    DEPLOY_ENV: "feature"
    APP_VERSION: "${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHORT_SHA}"
    DOCKER_TLS_CERTDIR: ""
  
  before_script: |
    # Authenticate with GitLab Container Registry for pulling
    echo "${CI_REGISTRY_PASSWORD}" | docker login --username "${CI_REGISTRY_USER}" --password-stdin "${CI_REGISTRY}"
    
    # Generate dynamic port based on branch hash (5001-5099 range)
    export DYNAMIC_PORT=$((5001 + (0x$(echo -n "$CI_COMMIT_REF_SLUG" | sha256sum | head -c 2) % 99)))
    echo "Deploying feature branch to dynamic environment..."
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Environment: review/$CI_COMMIT_REF_SLUG"
    echo "Dynamic Port: $DYNAMIC_PORT"
    
    # Update GitLab environment URL with actual dynamic port
    if [ -n "$CI_JOB_TOKEN" ] && [ -n "$CI_PROJECT_ID" ]; then
      ENVIRONMENT_URL="http://localhost:$DYNAMIC_PORT"
      echo "Updating GitLab environment URL to: $ENVIRONMENT_URL"
      
      curl -s --request PUT \
        --header "JOB-TOKEN: $CI_JOB_TOKEN" \
        --header "Content-Type: application/json" \
        --data "{\"external_url\": \"$ENVIRONMENT_URL\"}" \
        "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/environments/$(echo "review/$CI_COMMIT_REF_SLUG" | sed 's/\//%2F/g')" \
        || echo "Failed to update environment URL (this is non-critical)"
    fi

      # Create directory structure for deployment
    mkdir -p scripts/
    
    # Download deployment files from GitLab repository
    REPO_API_URL="${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/repository"

    echo "Downloading docker-compose-dev.yml..."
    curl -H "PRIVATE-TOKEN: ${CI_JOB_TOKEN}" \
         "${REPO_API_URL}/files/docker-compose.dev.yml/raw?ref=${CI_COMMIT_SHA}" \
         -o docker-compose.dev.yml
    
    echo "Downloading deploy.sh..."
    curl -H "PRIVATE-TOKEN: ${CI_JOB_TOKEN}" \
         "${REPO_API_URL}/files/scripts%2Fdeploy.sh/raw?ref=${CI_COMMIT_SHA}" \
         -o scripts/deploy.sh
    chmod +x scripts/deploy.sh

  script: |
    # Debug: Show current environment and available images
    echo "=== DEPLOYMENT DEBUG INFO ==="
    echo "CI_REGISTRY_IMAGE: ${CI_REGISTRY_IMAGE:-'not set'}"
    echo "IMAGE_NAME: ${IMAGE_NAME:-'not set'}"
    echo "Branch: $CI_COMMIT_BRANCH"
    echo "Commit SHA: $CI_COMMIT_SHA"
    echo "============================="
    
    # Use the built feature branch image (already available locally)
    BRANCH_TAG="${CI_COMMIT_REF_SLUG}"
    
    echo "Using local image: $CI_REGISTRY_IMAGE:$BRANCH_TAG"
    if docker image inspect $CI_REGISTRY_IMAGE:$BRANCH_TAG > /dev/null 2>&1; then
      docker tag $CI_REGISTRY_IMAGE:$BRANCH_TAG trakbridge:$BRANCH_TAG-latest
      echo "Successfully tagged local image"
    else
      echo "ERROR: Local image not found: $CI_REGISTRY_IMAGE:$BRANCH_TAG"
      echo "This usually means the build-feature-branch-shell job failed or didn't run"
      echo "Available images:"
      docker images | grep "$CI_REGISTRY_IMAGE"
      exit 1
    fi
    
    # Debug: Check current directory and file structure
    echo "=== FILE SYSTEM DEBUG ==="
    pwd
    echo "Contents of current directory:"
    ls -la
    echo "Looking for scripts directory:"
    ls -la scripts/ || echo "scripts directory not found"
    echo "Checking if deploy.sh exists:"
    find . -name "deploy.sh" -type f || echo "deploy.sh not found anywhere"
    echo "=========================="
    
    # Check if we need to use absolute path or if file exists
    if [ -f "./scripts/deploy.sh" ]; then
      chmod +x ./scripts/deploy.sh
      DEPLOY_SCRIPT="./scripts/deploy.sh"
    elif [ -f "$CI_PROJECT_DIR/scripts/deploy.sh" ]; then
      chmod +x "$CI_PROJECT_DIR/scripts/deploy.sh"
      DEPLOY_SCRIPT="$CI_PROJECT_DIR/scripts/deploy.sh"
    else
      echo "ERROR: scripts/deploy.sh not found in expected locations"
      echo "Checked:"
      echo "  - ./scripts/deploy.sh"
      echo "  - $CI_PROJECT_DIR/scripts/deploy.sh"
      exit 1
    fi
    
    echo "Using deploy script: $DEPLOY_SCRIPT"

    # Set environment variables for feature branch deployment
    export FEATURE_BRANCH_PORT=$DYNAMIC_PORT
    export FEATURE_BRANCH_NAME="$CI_COMMIT_REF_SLUG"
    export COMPOSE_PROJECT_NAME="trakbridge-$CI_COMMIT_REF_SLUG"
    
    # Export dynamic user variables for Docker runtime user creation
    export USER_ID=${USER_ID:-$(id -u)}
    export GROUP_ID=${GROUP_ID:-$(id -g)}
    
    # Export GitLab CI variables for Docker Compose
    echo "Exporting GitLab CI variables for Docker Compose..."
    export LDAP_SERVER="${LDAP_SERVER:-ldap://your-ad-server.company.com}"
    export LDAP_ENABLED="${LDAP_ENABLED:-false}"
    export LDAP_PORT="${LDAP_PORT:-389}"
    export LDAP_USE_SSL="${LDAP_USE_SSL:-false}"
    export LDAP_USE_TLS="${LDAP_USE_TLS:-false}"
    export LDAP_VALIDATE_CERT="${LDAP_VALIDATE_CERT:-false}"
    export LDAP_BIND_DN="${LDAP_BIND_DN:-CN=trakbridge,OU=Service Accounts,DC=company,DC=com}"
    export LDAP_BIND_PASSWORD="${LDAP_BIND_PASSWORD:-default-ldap-password}"
    export LDAP_USER_SEARCH_BASE="${LDAP_USER_SEARCH_BASE:-OU=Users,DC=company,DC=com}"
    export LDAP_USER_SEARCH_FILTER="${LDAP_USER_SEARCH_FILTER}"
    export LDAP_GROUP_SEARCH_BASE="${LDAP_GROUP_SEARCH_BASE:-OU=Groups,DC=company,DC=com}"
    export LDAP_GROUP_SEARCH_FILTER="${LDAP_GROUP_SEARCH_FILTER}"
    export LDAP_ADMIN_GROUP="${LDAP_ADMIN_GROUP:-CN=TrakBridge-Admins,OU=Groups,DC=company,DC=com}"
    export LDAP_OPERATOR_GROUP="${LDAP_OPERATOR_GROUP:-CN=TrakBridge-Operators,OU=Groups,DC=company,DC=com}"
    export LDAP_USER_GROUP="${LDAP_USER_GROUP:-CN=TrakBridge-Users,OU=Groups,DC=company,DC=com}"
    export LDAP_DEFAULT_ROLE="${LDAP_DEFAULT_ROLE:-user}"
    export LDAP_CONNECTION_TIMEOUT="${LDAP_CONNECTION_TIMEOUT:-10}"
    export LDAP_RESPONSE_TIMEOUT="${LDAP_RESPONSE_TIMEOUT:-30}"
    
    # OIDC/SSO Settings  
    export OIDC_ENABLED="${OIDC_ENABLED:-false}"
    export OIDC_ISSUER="${OIDC_ISSUER:-https://your-identity-provider.com}"
    export OIDC_CLIENT_ID="${OIDC_CLIENT_ID:-trakbridge-client}"
    export OIDC_CLIENT_SECRET="${OIDC_CLIENT_SECRET:-default-oidc-secret}"
    export OIDC_REDIRECT_URI="${OIDC_REDIRECT_URI:-http://localhost:5000/auth/oidc/callback}"
    export OIDC_VERIFY_SIGNATURE="${OIDC_VERIFY_SIGNATURE:-false}"
    export OIDC_VERIFY_AUDIENCE="${OIDC_VERIFY_AUDIENCE:-false}"
    export OIDC_VERIFY_ISSUER="${OIDC_VERIFY_ISSUER:-false}"
    export OIDC_ADMIN_GROUP="${OIDC_ADMIN_GROUP:-trakbridge-admins}"
    export OIDC_OPERATOR_GROUP="${OIDC_OPERATOR_GROUP:-trakbridge-operators}"
    export OIDC_USER_GROUP="${OIDC_USER_GROUP:-trakbridge-users}"
    export OIDC_DEFAULT_ROLE="${OIDC_DEFAULT_ROLE:-user}"
    
    echo "LDAP_SERVER will be set to: $LDAP_SERVER"
    echo "LDAP_BIND_PASSWORD length: ${#LDAP_BIND_PASSWORD}"
    echo "LDAP_BIND_PASSWORD first 10 chars: ${LDAP_BIND_PASSWORD:0:10}..."
    
    $DEPLOY_SCRIPT \
      --environment feature \
      --action deploy \
      --port $DYNAMIC_PORT \
      --profiles postgres \
      --timeout 300 \
      --branch "$CI_COMMIT_REF_SLUG" \
      --use-prebuilt \
      --skip-health-check \
      --verbose
    
    # Health check for the dynamic environment using Docker health status
    echo "Checking Docker container health status..."
    
    # Wait for container to be healthy (Docker's built-in health check)
    timeout 120 bash -c "
      while true; do
        container_health=\$(docker inspect --format='{{.State.Health.Status}}' ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} 2>/dev/null || echo 'none')
        echo \"Container health status: \$container_health\"
        
        case \$container_health in
          'healthy')
            echo 'Container is healthy!'
            exit 0
            ;;
          'unhealthy')
            echo 'Container is unhealthy!'
            exit 1
            ;;
          'starting'|'none')
            echo 'Container is still starting, waiting...'
            sleep 10
            ;;
          *)
            echo 'Unknown health status, waiting...'
            sleep 10
            ;;
        esac
      done
    "
    
    # Additional verification with direct API call
    if curl -f http://localhost:$DYNAMIC_PORT/api/health; then
      echo "Feature branch deployment verified successfully"
    else
      echo "Feature branch deployment verification failed"
      echo "=== CONTAINER LOGS FOR DEBUGGING ==="
      echo "--- Application Container Logs ---"
      docker logs ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} --tail=50 || echo "Could not get app container logs"
      echo "--- PostgreSQL Container Logs ---"
      docker logs ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG}-postgres --tail=20 || echo "Could not get postgres container logs"
      echo "--- Container Status ---"
      docker ps --filter "name=${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG}" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
      echo "=== END CONTAINER LOGS ==="
      exit 1
    fi
    
    # Debug: Check environment variables inside the container
    echo "=== CONTAINER ENVIRONMENT DEBUG ==="
    docker exec ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} env | grep LDAP || echo "No LDAP environment variables found"
    echo "Container LDAP_BIND_PASSWORD length:"
    docker exec ${COMPOSE_PROJECT_NAME:-trakbridge-$CI_COMMIT_REF_SLUG} sh -c 'echo ${#LDAP_BIND_PASSWORD}' || echo "LDAP_BIND_PASSWORD not set in container"
    echo "=== END CONTAINER DEBUG ==="
    
    echo "Feature branch deployment completed"
    echo "Feature Branch URL: http://localhost:$DYNAMIC_PORT"
    echo "Default login: admin / TrakBridge-Setup-2025!"
    echo "Environment: review/$CI_COMMIT_REF_SLUG"
    
    # Generate feature branch deployment health report
    cat > deployment-health-report.json << EOF
    {
      "deployment": {
        "environment": "feature",
        "feature_branch": "$CI_COMMIT_REF_SLUG",
        "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
        "status": "success",
        "url": "http://localhost:$DYNAMIC_PORT",
        "port": $DYNAMIC_PORT,
        "version": "${CI_COMMIT_SHA}",
        "branch": "${CI_COMMIT_BRANCH}"
      },
      "health_checks": [],
      "metrics": {
        "deployment_duration": "${SECONDS:-0}",
        "containers_running": 0
      }
    }
    EOF
    
    # The health check was already performed above, record the result
    if curl -f http://localhost:$DYNAMIC_PORT/api/health > health-response.json 2>/dev/null; then
      jq '.health_checks += [{"name": "feature_api_health", "status": "pass", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "port": '$DYNAMIC_PORT'}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
    else
      jq '.health_checks += [{"name": "feature_api_health", "status": "fail", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "port": '$DYNAMIC_PORT'}]' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
      jq '.deployment.status = "failed"' deployment-health-report.json > temp.json && mv temp.json deployment-health-report.json
    fi
  
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: manual
      allow_failure: true
  
  dependencies:
    - build-feature-branch-shell
    - cleanup-build-artifacts

  artifacts:
    paths:
      - deployment-health-report.json
      - health-response.json
    expire_in: 1 week
    when: always

# Stop feature branch environment (cleanup)
stop-feature-branch:
  stage: deploy
  tags:
    - trakbridge-cd
  timeout: 15m
  
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    action: stop
  
  variables:
    DEPLOY_ENV: "feature"
    DOCKER_TLS_CERTDIR: ""
  
  script: |
    # Generate dynamic port based on branch hash (same calculation as deploy)
    export DYNAMIC_PORT=$((5001 + (0x$(echo -n "$CI_COMMIT_REF_SLUG" | sha256sum | head -c 2) % 99)))
    echo "Stopping feature branch environment..."
    echo "Environment: review/$CI_COMMIT_REF_SLUG"
    echo "Port: $DYNAMIC_PORT"
    
    # Stop and clean up the feature branch deployment

    export COMPOSE_PROJECT_NAME="trakbridge-$CI_COMMIT_REF_SLUG"
    export FEATURE_BRANCH_PORT=$DYNAMIC_PORT
    export FEATURE_BRANCH_NAME="$CI_COMMIT_REF_SLUG"
      
    # Find and use deployment script to clean up
    if [ -f "./scripts/deploy.sh" ]; then
      chmod +x ./scripts/deploy.sh
      DEPLOY_SCRIPT="./scripts/deploy.sh"
    elif [ -f "$CI_PROJECT_DIR/scripts/deploy.sh" ]; then
      chmod +x "$CI_PROJECT_DIR/scripts/deploy.sh"
      DEPLOY_SCRIPT="$CI_PROJECT_DIR/scripts/deploy.sh"
    else
      DEPLOY_SCRIPT=""
    fi
    
    if [ -n "$DEPLOY_SCRIPT" ]; then
      echo "Using deployment script for cleanup: $DEPLOY_SCRIPT"
      $DEPLOY_SCRIPT \
        --environment feature \
        --action stop \
        --port $DYNAMIC_PORT \
        --branch "$CI_COMMIT_REF_SLUG" \
        --use-prebuilt \
        --verbose
    else
      # Fallback cleanup if script not available
      echo "Deployment script not found, using fallback cleanup..."
      docker compose -p "trakbridge-$CI_COMMIT_REF_SLUG" down -v || echo "No containers to stop"
      
      # Clean up any containers on the dynamic port
      docker ps -q --filter "publish=$DYNAMIC_PORT" | xargs -r docker stop || echo "No containers on port $DYNAMIC_PORT"
    fi
    
    echo "Feature branch environment stopped and cleaned up"
  
  rules:
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: manual
  
  dependencies: []

# =============================================================================
# FINAL CLEANUP STAGE - Complete Workspace Cleanup After All Operations
# =============================================================================

# Final cleanup after entire pipeline completion
final-workspace-cleanup:
  stage: final-cleanup
  image: alpine:latest
  tags:
    - trakbridge-ci
  timeout: 5m
  
  script: |
    echo "🧹 Final workspace cleanup after entire pipeline completion..."
    
    # Complete workspace cleanup - remove everything
    echo "Performing final workspace wipe..."
    rm -rf ./* .[^.]* ..?* 2>/dev/null || true
    
    # Clean up any Docker artifacts if Docker is available
    if command -v docker >/dev/null 2>&1; then
      echo "Cleaning up Docker artifacts..."
      docker system prune -f --volumes 2>/dev/null || true
    fi
    
    # Final verification
    echo "=== FINAL VERIFICATION - Workspace after complete pipeline cleanup ==="
    ls -la
    echo ""
    echo "✅ Final workspace cleanup completed - CI runner is clean"
  
  rules:
    - if: $CI_COMMIT_TAG
      when: always
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: always
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      when: always
  
  # Always run cleanup regardless of previous job failures
  when: always

# =============================================================================
# NOTIFICATIONS - Discord Webhook Notifications on Pipeline Success/Failure
# ============================================================================= 
success_notification:
  stage: notification
  script:
    - wget https://raw.githubusercontent.com/DiscordHooks/gitlab-ci-discord-webhook/master/send.sh
    - chmod +x send.sh
    - ./send.sh success $DISCORD_WEBHOOK_URL
  when: on_success
  dependencies:
    - code-quality-check      # Links: gl-code-quality-report.json, black/flake8/isort outputs
    - unit-tests              # Links: coverage reports, test results, htmlcov/
    - integration-tests       # Links: integration test results
    - security-scan          # Links: bandit-report.json, dependency scanning
    - license-scan           # Links: license reports  
    - production-release     # Links: production release report (if applicable)
    - staging-validation     # Links: staging test results (if applicable)
  artifacts:
    paths:
      - "*.json"              # Capture any summary reports
      - "*.xml"
    expire_in: 1 week

failure_notification:
  stage: notification
  script:
    - wget https://raw.githubusercontent.com/DiscordHooks/gitlab-ci-discord-webhook/master/send.sh
    - chmod +x send.sh
    - ./send.sh failure $DISCORD_WEBHOOK_URL
  when: on_failure
  dependencies:
    # Include jobs that might have diagnostic artifacts even on failure
    - code-quality-check
    - unit-tests
    - security-scan
  artifacts:
    paths:
      - "*.json"
      - "*.txt"
      - logs/
    expire_in: 3 days
    when: always

# =============================================================================
# PIPELINE COMPLETION
# =============================================================================

# Pipeline completion summary
pipeline-complete:
  stage: .post
  image: alpine:latest
  tags:
    - trakbridge-ops
  timeout: 2m
  script: |
    echo "TrakBridge GitLab CI/CD Pipeline completed successfully!"
    echo ""
    echo "Pipeline Summary:"
    echo "- Pipeline ID: $CI_PIPELINE_ID"
    echo "- Commit: $CI_COMMIT_SHA"
    echo "- Branch/Tag: ${CI_COMMIT_TAG:-$CI_COMMIT_REF_NAME}"
    echo "- Pipeline URL: $CI_PIPELINE_URL"
    echo ""
    
    if [ "$CI_COMMIT_BRANCH" == "$CI_DEFAULT_BRANCH" ] && [ -z "$CI_COMMIT_TAG" ]; then
      echo "  Development deployment completed"
      echo "   Built dev image: $IMAGE_NAME:dev"
      if [ -n "$CI_REGISTRY_IMAGE" ]; then
        echo "   GitLab Container Registry: $CI_REGISTRY_IMAGE:dev"
      fi
      echo "   Application URL: http://localhost:5000"
    elif [ -n "$CI_COMMIT_TAG" ]; then
      echo "  📦 Release pipeline for tagged version: $CI_COMMIT_TAG"  
      echo "   ✅ Built multiplatform image: $CI_REGISTRY_IMAGE:$CI_COMMIT_TAG"
      echo "   🔍 Staging validation: Automatic comprehensive testing"
      echo "   🚀 DockerHub publication: Manual approval required"
      echo ""
      echo "   🔗 Release workflow:"
      echo "   1. Build → GitLab Container Registry (completed)"
      echo "   2. Staging validation → All database types (automatic)"
      echo "   3. DockerHub publication → Manual trigger (requires approval)"
      echo ""
      echo "   📋 Next steps:"
      echo "   - Monitor staging validation progress"
      echo "   - Manually approve DockerHub publication after validation passes"
    elif [ "$CI_COMMIT_BRANCH" != "$CI_DEFAULT_BRANCH" ] && [ -z "$CI_COMMIT_TAG" ]; then
      echo "  Feature branch validation completed"
      echo "   Branch: $CI_COMMIT_BRANCH"
      echo "   Built image: $IMAGE_NAME:$CI_COMMIT_REF_SLUG"
      if [ -n "$CI_REGISTRY_IMAGE" ]; then
        echo "   GitLab Container Registry: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG"
      fi
      echo "   Deploy manually using the 'deploy-feature-branch' job to test your changes"
      echo "   Feature deployments use dynamic ports (5001-5099 range)"
    else
      echo "  Code quality and security validation completed"
      echo "   Branch: $CI_COMMIT_BRANCH"
      echo "   All quality gates passed successfully"
    fi
    
    echo ""
    echo "  View detailed results: $CI_PIPELINE_URL"
    echo ""
    echo "   Slack notifications are configured through GitLab's native Slack app integration."
    echo "   Visit Project Settings > Integrations > GitLab for Slack app to configure notifications."
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_TAG
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH
  when: on_success

# =============================================================================
# INCLUDE TEMPLATES - GitLab Security Templates (Enhanced)
# =============================================================================

# Include GitLab's built-in security scanning templates
# Note: License-Scanning.gitlab-ci.yml was deprecated in GitLab 15.9 and removed in 16.3
# License compliance is now handled through Dependency-Scanning.gitlab-ci.yml
# Container-Scanning.gitlab-ci.yml removed - using custom Trivy implementation instead
include:
  - template: Security/SAST.gitlab-ci.yml
  - template: Security/Dependency-Scanning.gitlab-ci.yml
  - template: Security/Secret-Detection.gitlab-ci.yml

# Override GitLab security templates to use TrakBridge runner tags
sast:
  stage: security
  tags:
    - trakbridge-ci

gemnasium-dependency_scanning:
  stage: security  
  tags:
    - trakbridge-ci

container_scanning:
  stage: security
  tags:
    - trakbridge-cd  # Needs Docker daemon access for container scanning
  timeout: 15m
  variables:
    CS_DOCKERFILE_PATH: "Dockerfile"
  before_script: |
    # Clean up any root-owned directories that may interfere with scanning
    echo "Cleaning up GitLab build directory permissions..."
    sudo find . -type d -name "data" -exec chmod 755 {} \; 2>/dev/null || true
    sudo find . -type d -name "logs" -exec chmod 755 {} \; 2>/dev/null || true
    sudo chown -R gitlab-runner:gitlab-runner data logs 2>/dev/null || true
  script: |
    echo "Running Trivy container scanning on $CS_IMAGE"
    if [ -n "$CS_IMAGE" ]; then
      # Create default report structure for GitLab compatibility
      echo '{"vulnerabilities": []}' > gl-container-scanning-report.json
      
      # Run Trivy scan with GitLab format
      trivy image --format json --output trivy-report.json "$CS_IMAGE" || echo "Trivy scan completed with warnings"
      
      # If Trivy found vulnerabilities, use its output
      if [ -f "trivy-report.json" ] && [ -s "trivy-report.json" ]; then
        mv trivy-report.json gl-container-scanning-report.json
      fi
      
      echo "Container scanning completed for $CS_IMAGE"
    else
      echo "No container image specified for scanning"
    fi
  artifacts:
    reports:
      container_scanning: gl-container-scanning-report.json
    paths:
      - gl-container-scanning-report.json
    when: always
    expire_in: 1 week
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      needs: ["build-image-shell"]
      variables:
        CS_IMAGE: "$IMAGE_NAME:$CI_COMMIT_SHA"
    - if: $CI_COMMIT_TAG
      needs: ["build-tagged-image-shell"]  
      variables:
        CS_IMAGE: "$IMAGE_NAME:$CI_COMMIT_TAG"
    - if: $CI_COMMIT_BRANCH && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH && $CI_COMMIT_TAG == null
      needs: ["build-feature-branch-shell"]
      variables:
        CS_IMAGE: "$IMAGE_NAME:$CI_COMMIT_REF_SLUG"

.secret-analyzer:
  stage: security
  tags:
    - trakbridge-ci